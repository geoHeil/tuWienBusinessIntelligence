{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manual retry\n",
    "WARNING:\n",
    "https://github.com/IRkernel/IRkernel needs to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import utils\n",
    "import skutils\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "gSeed = 47\n",
    "\n",
    "# Use ggplot style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big = pd.read_csv('train.csv')\n",
    "#test = pd.read_csv('test.csv')\n",
    "\n",
    "big.species = big.species.astype('category')\n",
    "big.species = big.species.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    ID = data.id\n",
    "    X = data.drop(['species', 'id'], axis=1)\n",
    "    y = data['species']\n",
    "    return ID, X, y\n",
    "\n",
    "ID, X, y = transform(big)\n",
    "\n",
    "def addZeroColumn(df, colName):\n",
    "    df.loc[df[colName] < 0.01, colName + '_is_small'] = 1\n",
    "    df[colName + '_is_small'].fillna(0, inplace=True)\n",
    "\n",
    "def addZeroColumns(df, colBaseName):\n",
    "    for n in range(1,65):\n",
    "        addZeroColumn(df, colBaseName + str(n))\n",
    "        \n",
    "addZeroColumns(X, 'margin')\n",
    "addZeroColumns(X, 'texture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: \n",
      "Attache Paket: ‘MLmetrics’\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: The following object is masked from ‘package:base’:\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "# use the R function to create all the same evaluation metrics\n",
    "library(MLmetrics)\n",
    "\n",
    "evaluateModel <- function(data,results) {\n",
    "  # data: real NEVERPAYER column (actual values)\n",
    "  # results: predicted NEVERPAYER column (predicted values)\n",
    "  \n",
    "  confMatrix <- table(data,results)\n",
    "  print(confMatrix)\n",
    "  \n",
    "  err <- (confMatrix[\"J\",\"N\"]+confMatrix[\"N\",\"J\"])/sum(confMatrix)  \n",
    "  acc <- (confMatrix[\"J\",\"J\"]+confMatrix[\"N\",\"N\"])/sum(confMatrix)  \n",
    "  \n",
    "  tpr <- confMatrix[\"J\",\"J\"]/(confMatrix[\"J\",\"J\"]+confMatrix[\"J\",\"N\"]) \n",
    "  tnr <- confMatrix[\"N\",\"N\"]/(confMatrix[\"N\",\"N\"]+confMatrix[\"N\",\"J\"]) \n",
    "  \n",
    "  ppv <- confMatrix[\"J\",\"J\"]/(confMatrix[\"J\",\"J\"]+confMatrix[\"N\",\"J\"]) \n",
    "  npv <- confMatrix[\"N\",\"N\"]/(confMatrix[\"N\",\"N\"]+confMatrix[\"J\",\"N\"]) \n",
    "  \n",
    "  fpr <- confMatrix[\"N\",\"J\"]/(confMatrix[\"N\",\"N\"]+confMatrix[\"N\",\"J\"]) \n",
    "  fnr <- confMatrix[\"J\",\"N\"]/(confMatrix[\"J\",\"J\"]+confMatrix[\"J\",\"N\"]) \n",
    "  \n",
    "  rpp <- (confMatrix[\"J\",\"J\"]+confMatrix[\"N\",\"J\"])/sum(confMatrix) \n",
    "  rnp <- (confMatrix[\"J\",\"J\"]+confMatrix[\"J\",\"N\"])/sum(confMatrix) \n",
    "    \n",
    "  kappa <- vcd::Kappa(confMatrix)\n",
    "  kappa <- kappa$Unweighted[1]\n",
    "  names(kappa) <- c(\"kappa\") \n",
    "  \n",
    "  lift <- tpr/rpp\n",
    "  \n",
    "  names(err) <- c(\"Error rate\")\n",
    "  names(acc) <- c(\"Accuracy\")\n",
    "  names(tpr) <- c(\"Sensitivity (true positives rate)\")\n",
    "  names(tnr) <- c(\"Specificity (true negatives rate)\")\n",
    "  names(ppv) <- c(\"Precision J\")\n",
    "  names(npv) <- c(\"Precision N\")\n",
    "  names(fpr) <- c(\"False positive rate\")\n",
    "  names(fnr) <- c(\"False negative rate\")\n",
    "  names(rpp) <- c(\"Rate of positive predictions\")\n",
    "  names(rnp) <- c(\"Rate of negative predictions\")\n",
    "  names(lift) <- c(\"Lift value\")\n",
    "\n",
    "  results <- list(err,acc,tpr,tnr,ppv,npv,fpr,fnr,rpp,rnp,lift, kappa)\n",
    "  results\n",
    "}\n",
    "\n",
    "evaluateAllTheThings <- function(groundTruth, prediction){\n",
    "    f1 <- MLmetrics::F1_Score(y_pred = prediction, y_true = groundTruth)\n",
    "    auc <- MLmetrics::AUC(y_pred = prediction, y_true = groundTruth)\n",
    "    names(f1) <- c(\"f1_R\") \n",
    "    names(auc) <- c(\"AUC_R\")\n",
    "\n",
    "    predictionJN <- ifelse(prediction == 0,\"N\",\"J\")\n",
    "    groundTruthJN <- ifelse(groundTruth == 0,\"N\",\"J\")\n",
    "\n",
    "    evalA <- evaluateModel(groundTruthJN,predictionJN)\n",
    "    \n",
    "    index <- length(evalA)+1\n",
    "\n",
    "    evalA[[index]] <- f1\n",
    "    evalA[[index+1]] <- auc\n",
    "    \n",
    "    evalA\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_str(val):\n",
    "    return str(val).split('\"')[1]\n",
    "\n",
    "\n",
    "def flatten_dict(d, prefix='__'):\n",
    "    def items():\n",
    "        for key, value in d.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, sub_value in flatten_dict(value).items():\n",
    "                    yield sub_key, sub_value\n",
    "            else:\n",
    "                yield key, value\n",
    "\n",
    "    return dict(items())\n",
    "\n",
    "\n",
    "class Observation():\n",
    "    def __init__(self):\n",
    "        self.statValues = {}\n",
    "        self.modelName = \"\"\n",
    "\n",
    "    def setModelName(self, nameOfModel):\n",
    "        self.modelName = nameOfModel\n",
    "\n",
    "    def addStatMetric(self, metricName, metricValue):\n",
    "        self.statValues[metricName] = metricValue\n",
    "\n",
    "def evalSingleModel(X, y_test, clf, modelName, variant, _verbose):\n",
    "    y_predicted = clf.predict(X)\n",
    "\n",
    "    if(_verbose):\n",
    "        print(classification_report(y_test, y_predicted))\n",
    "    # send the data to R\n",
    "    groundTruth = y_test.values\n",
    "\n",
    "    %Rpush groundTruth\n",
    "    %Rpush y_predicted\n",
    "    %R res <- evaluateAllTheThings(groundTruth, y_predicted)\n",
    "    %Rpull res\n",
    "    statsResults = dict([[to_str(j.names),j[0]] for i,j in enumerate(res)])\n",
    "    obs = Observation()\n",
    "    obs.setModelName(modelName + '-' + variant)\n",
    "    \n",
    "    for _kpi, value in statsResults.items():\n",
    "        obs.addStatMetric(_kpi, value)\n",
    "        \n",
    "    obs.addStatMetric('typeOfRun', variant)\n",
    "    if(_verbose):\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(statsResults)\n",
    "    return obs\n",
    "\n",
    "def splitOffValidation(X, y, _seed):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=_seed)\n",
    "    for train_index, test_index in split.split(X, y):\n",
    "        X_work = X.iloc[train_index]\n",
    "        X_validation = X.iloc[test_index]\n",
    "        y_work = y.iloc[train_index]\n",
    "        y_validation = y.iloc[test_index]\n",
    "    return X_work, X_validation, y_work, y_validation\n",
    "\n",
    "def evaluateCV(X, y, pipeline, labelData,allResultsOfModels,_seed, _verbose=True):\n",
    "    X_work, X_validation, y_work, y_validation = splitOffValidation(X, y, _seed)\n",
    "    ##############################################################\n",
    "    ### Train /Test\n",
    "    split = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=_seed)\n",
    "    foldCounter = 0\n",
    "    for train_index, test_index in split.split(X_work, y_work):\n",
    "        foldCounter += 1\n",
    "        if _verbose:\n",
    "            print(\"###################### Training Fold: \", foldCounter, \" #################\")\n",
    "        if _verbose:\n",
    "            print(\"TRAIN:\", train_index)\n",
    "            print(\"TEST:\", test_index)\n",
    "        X_train = X_work.iloc[train_index]\n",
    "        X_test = X_work.iloc[test_index]\n",
    "        \n",
    "        y_train = y_work.iloc[train_index]\n",
    "        y_test = y_work.iloc[test_index]\n",
    "        X_validationCopy = X_validation.copy()\n",
    "    \n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        allResultsOfModels.append(evalSingleModel(X_test, y_test, pipeline, labelData + '_' + str(foldCounter), 'training', _verbose))\n",
    "    #############################################################\n",
    "    ### Evaluation on validation set\n",
    "    \n",
    "    if _verbose:\n",
    "        print(\"###################### Validation #################\")\n",
    "    \n",
    "    pipeline.fit(X_work, y_work)\n",
    "    allResultsOfModels.append(evalSingleModel(X_validation, y_validation, pipeline, labelData, 'validation', _verbose))\n",
    "    \n",
    "allResultsOfModels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Training Fold:  1  #################\n",
      "TRAIN: [259  47  82 636  26 214 403  90 233 238 548 545 110 107 602 480 489 577\n",
      "  76 404 285 437 321  19  49 376  94 179 339 184 518 278 477 302 616 325\n",
      " 269 505 597 328 303 108 315 239 603 375  23 447 443 247 438 526 287 389\n",
      " 473 309 654  53 326 401 406 614 360 103 204 691 161 196 413   2 252 296\n",
      " 139 546 352 164 222 255 588 445 240 387  61 324 400 642 689 384 685 386\n",
      " 385 142 610 573 323 116 237 688  13 529  12 193  38  21 618 169 576 319\n",
      " 419 200   1 536 390 498 405 591 253 106 297 595 146 645 230 551 686 510\n",
      " 417 305 635 147 673 219 207 580 589 647 598 145 575 683 436 607 687 463\n",
      " 335  98 590 348 371 260 366 102 329 659 538 478  68 135 332 535 649 216\n",
      " 118 148 249 264 513 220 350 630 322  22 481 410 679 664 369  67 359 173\n",
      " 676 677 364 560 458 640 428 354 308  25  99 265 425 583 675 578 631  40\n",
      " 609 572 275  42 327 137 494 474 632 236 104 316 355  74 562 493  96 351\n",
      " 579 454 221 225 215 550 430 307 243 509 465 623  29 434 246  70 248 564\n",
      " 188  43 584 121 619 592 279 626 429 358 310 461 608  51 158 251 210 208\n",
      " 521 337  18 189   3  87 605 198  45 657 557 144 462 128 368 650 585 422\n",
      " 668 639 467 166 136 431 561 581 268 213   7  48 460 459 342 484 133 163\n",
      " 625 276 427  66 289 500 211 205  84 171 490  85 541 441 228 370 520 217\n",
      "  33 658  71 497 101 112 209 257 690 270 661 154 274 178 168  11 183 180\n",
      "  36 442  54 582 641 331 418   4 301 120 347 516 411 453 123 314 398  20\n",
      " 680 338 267 671 363 499 244 292 254 399  60 201 129 311 586 555 334 306\n",
      "  41 446 122 496 312 195 113 132 486  28  39 402  83 552 667 502 457  31\n",
      " 504 432  37 124 416 141 258 559 440 522 320 483 570 670 318 615 512  81\n",
      " 622  91 345 190  73 503  14 469 563 448 397 666 515 256 476 382 556 170\n",
      " 524 672  30 565 153 596 415 391 280 553 151 381 523 160 420 606 261 177\n",
      " 333 250  15 451 514 388  80 293 298 525 374  16 452 519 140 628 466 235\n",
      " 234 115 199 353 127 629 611 242 284 681 542 472 554  44 627 421 669  86\n",
      " 537   6  58 282 624 435 464 149 223 507  46 485 471 343 152 232 587 372\n",
      " 143 373  95 150 468 612 245 684 449 186 156 271 291 633 648 336  17 362\n",
      "  63  75 495 674  24 450 660 229 692 218 356 534  55 288 568 299 617 277\n",
      "  62 126 346 224 549  34 662 138 599 424 377 527 656 130 558 172 175 569\n",
      " 479 407 367 604 165 528 341  93 176 157 203 117 531 530]\n",
      "TEST: [621  52 349 634 286 294 600 379   9 655 185 131  69 506 281  59 492 539\n",
      " 226 361 393 159 197 273 533 456 272 517 304  10 111 601 544 182 194 383\n",
      " 665 392 357 174 511 652 547  88  78 192 105  77 653 365  27 423 433  50\n",
      "  57 426 482 340 283 414 593 439 501 409 119 181  35 643 162 444 571 290\n",
      " 644 227 637 470 395 620 206   5 594 125 167 663  92 155 114 613 241 567\n",
      " 638 263 566 678 212 330 488  89 412 109 191 396 646 540 532  64 682  72\n",
      " 491 187 380 134 408 378 317 344 394 475  65 651   0 266 574  32 313 262\n",
      " 202 300  56 100  79   8 487 455 543 508  97 295 231]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.67      1.00      0.80         2\n",
      "          7       1.00      1.00      1.00         2\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       0.50      1.00      0.67         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       0.50      1.00      0.67         1\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       0.50      1.00      0.67         1\n",
      "         19       1.00      0.50      0.67         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       0.50      0.50      0.50         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       0.50      1.00      0.67         1\n",
      "         26       0.50      1.00      0.67         1\n",
      "         27       0.67      1.00      0.80         2\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       0.50      1.00      0.67         1\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      0.50      0.67         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       0.00      0.00      0.00         1\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       0.50      0.50      0.50         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       0.33      0.50      0.40         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         2\n",
      "         46       0.50      1.00      0.67         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       0.50      0.50      0.50         2\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         2\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      0.50      0.67         2\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         2\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       0.00      0.00      0.00         1\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       0.50      1.00      0.67         1\n",
      "         64       1.00      0.50      0.67         2\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       0.67      1.00      0.80         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       0.50      0.50      0.50         2\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         2\n",
      "         73       0.67      1.00      0.80         2\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         1\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       0.00      0.00      0.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       0.50      1.00      0.67         1\n",
      "         80       0.50      0.50      0.50         2\n",
      "         81       0.00      0.00      0.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      0.50      0.67         2\n",
      "         84       0.00      0.00      0.00         1\n",
      "         85       0.00      0.00      0.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       0.00      0.00      0.00         1\n",
      "         92       1.00      0.50      0.67         2\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         2\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       0.50      0.50      0.50         2\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      0.50      0.67         2\n",
      "\n",
      "avg / total       0.79      0.81      0.78       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 137   1\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 2.0,\n",
      "    'Accuracy': 0.9928057553956835,\n",
      "    'Error rate': 0.007194244604316547,\n",
      "    'False negative rate': 0.007246376811594203,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.5,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9856115107913669,\n",
      "    'Sensitivity (true positives rate)': 0.9927536231884058,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.6666666666666666,\n",
      "    'kappa': 0.6634382566585989}\n",
      "###################### Training Fold:  2  #################\n",
      "TRAIN: [ 60 545 625 533  59 355 423 159 223 577 576 688  95 510 397 572  31 135\n",
      " 569 131 132 670 518  24 101 403 421 580 202 118   8 324 493 316  28 386\n",
      " 331 283 342 557 371 548 608 246  26 477 140 327 547 542 116 393 516 687\n",
      " 419 384 514 619 685 320 626 263 230 220 537 663   3 359 609  61 178 473\n",
      " 275 165 413 366 242 334 241 388 245 554 189 385 147 161 254 375 104 219\n",
      " 322 158 156 229 314 185 534 471 170 374 236 679 148 425 635 402 370 566\n",
      " 134 206 458 109 672 201  14 112   6 631 356 108 553 440 442 650 532 523\n",
      " 240  78 428  65 596  68 188 522 344 529  15 507 164 309 207 111  62  47\n",
      " 225 456 676  79 346 265 612 204 372 573 315  46 610 298 466 658 279 262\n",
      " 336 556  45 352 292 330 427  92 335  20 377 105 227 571 150  77 253 239\n",
      " 416 486 152 361  97 287 200 648 181 209 605 248  16 485  90 464 463 321\n",
      "  44 653 490 291 226 367 409 351  22 126 447 468 628  23 302 614 677  70\n",
      " 203 494 461  98 412 382 600  89 141  48 599 592 435 482 681 665 686 368\n",
      " 607 271 338 124 536 399 329 660 296 535 669 347 299 520  17 127 401 583\n",
      " 266  30 594 396 100   5 357 293 429 255 137 678 661 638 110 656 551  32\n",
      " 671 662  36 667  84 527 167 570   9  11 373 192 268 378  21 325  71 153\n",
      " 142 125 515 474 475  88 213 211 252 593 323 417 459  85 630 273  49  34\n",
      " 197 251 146 564 308  43  27 647 117 404 179 524 106 622 243 654 567 505\n",
      " 651 363 272 615 233 457 139 469 546  58 646  52  82 684 284 163 232 604\n",
      " 280 247 629 389 636 343  81  25 295 282 176 645 184 180 205 301 381 496\n",
      " 528 666 640 438 526  80 632 174 587 129 103 581 519 151 391 261 194 306\n",
      " 414 613 540 358  94 387 171 216 281 168 437 237 285 379 649  96 568 531\n",
      "  73 395 655 328 310 289 467 563  67 668 269 208 274 392 465 480 345 339\n",
      " 349 543 256 470  13 113 606 492 598  86 498 138 657 380 495 445 133 588\n",
      "  64 286  53 362 578  41 595   7 664 452 639 579 460 172 259 508 405 186\n",
      " 673 430 513 652 191 487 506 297 511 276 637 503 530 597 177 602 642 154\n",
      " 446 582 173 434 144 122 476 128 221 558 199  40 149 586 365 411 311 319\n",
      " 589 250 674   0 267 305 680 210 683 394 478 364 264  56 549 552 538 340\n",
      " 644 317 341 488 257 472  69 618 258 449 483 585 584 641 621  38 212 634\n",
      " 623 214 541 182  87 198 611 155 224 443 406  83 410 432  12 555 120  50\n",
      "  37 217 190 222 484 659 290  18  57 294 517  93 574  39]\n",
      "TEST: [560 633 196 682 499  99  63 624   4  72 383 575 145 115 479 376 193 455\n",
      " 603 157  74 422 162 565 502 119 260 509 143 195 307 183 512 400 121  29\n",
      " 408 433 692 249  66 544 561  51 114 617 444 616 441  54 107 675 431  91\n",
      " 350 420 453 500 278 643 539  33 439 559 691 244 228 489  10 407   2  35\n",
      " 450  55 231 426   1 169  19 497 313 601 166 690 360 415 348 451 521 454\n",
      " 504 187 218 123 369 525 130 160 288 332  42 175 501 238  75 354 300 326\n",
      " 448 318 215 102 390 136 562 424 418 303 333 627 337 353 462 491 689 270\n",
      " 590 620 481  76 304 398 436 312 234 550 277 235 591]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.50         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       0.50      1.00      0.67         1\n",
      "          8       0.67      1.00      0.80         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      0.50      0.67         2\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       0.50      1.00      0.67         1\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         2\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       0.50      1.00      0.67         1\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       0.67      1.00      0.80         2\n",
      "         27       0.33      1.00      0.50         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.50      0.50      0.50         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       0.67      1.00      0.80         2\n",
      "         32       0.50      1.00      0.67         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       0.50      0.50      0.50         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       0.50      1.00      0.67         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       0.00      0.00      0.00         2\n",
      "         44       0.00      0.00      0.00         1\n",
      "         45       0.50      1.00      0.67         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       0.00      0.00      0.00         1\n",
      "         49       0.00      0.00      0.00         1\n",
      "         50       0.00      0.00      0.00         1\n",
      "         51       0.50      1.00      0.67         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       1.00      1.00      1.00         2\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       0.00      0.00      0.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       1.00      0.50      0.67         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       0.50      1.00      0.67         2\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       0.00      0.00      0.00         1\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      0.50      0.67         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         2\n",
      "         84       0.00      0.00      0.00         2\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       0.00      0.00      0.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       0.50      1.00      0.67         1\n",
      "         97       1.00      0.50      0.67         2\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.79      0.83      0.79       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 136   2\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 3.0,\n",
      "    'Accuracy': 0.9856115107913669,\n",
      "    'Error rate': 0.014388489208633094,\n",
      "    'False negative rate': 0.014492753623188406,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.3333333333333333,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9784172661870504,\n",
      "    'Sensitivity (true positives rate)': 0.9855072463768116,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.5,\n",
      "    'kappa': 0.4945454545454513}\n",
      "###################### Training Fold:  3  #################\n",
      "TRAIN: [303 265 624 674 245 237 318  95 326 185 684 194 594 430 389 156 466 181\n",
      " 532 440 545 484 372 396 319 304 288  93 508 554 480  53 541 160 147 201\n",
      "   7 282 671 112 353 313 685 277 455 118 115 366  14 370 168 576 240 321\n",
      " 100 457 272 470 563 512 391 469 641 433 505  83 511   5 598 579 578 485\n",
      " 179 510 187 445 335 311 121 424 681 535 668  85 141 442 346 395 174 154\n",
      " 622  21 359 356 306 124 271 300 384  28 127 233  27  56 244 342 294 247\n",
      " 489 191 157 661 580 189 268 279 357 524 553 677 534 439 199 566 574 648\n",
      " 162 586  47 527 299 295  29 497  38 522 315 134 205 453   2 352 226 669\n",
      " 537 239  74  84 167 613 248 130 341   9 290 230 241 166 436 149 418  98\n",
      " 324 452 689 549 110 544 498  79 273 256 642 657 583 155 362 413 672 556\n",
      " 336 555 645 634 109 292 612 582 519  25 478 246 429 591 293 210  88 640\n",
      " 231 264 656 653 261 600 621 219 632 597  26 285 437 255 158 302  17 172\n",
      " 216 493   8 678  99 595 540 459 548 159 287 609 142 523 388 468 416 655\n",
      " 354  68 373   6  16 680 573 676 441 517 317 463 471 664 111 203 136 536\n",
      " 325 368 587 581 456  10 514  23 606 351 575 107 611 284 164 120  13 490\n",
      " 108 410  40 102 647 329 137 636 506 350 492 281 253 197  50 165 660 259\n",
      " 267 467 531 486 398 371 675 177 358 667 617  72 589 116 687 665 525  96\n",
      " 228 148 599 559 192 666 499 592 417 626 561 420  80 569 250 151 454 590\n",
      " 101 390 236 243   0 360 296  33 215 494 334 331 602 383 328 227 627  62\n",
      " 218 135 616 402 422 211 403 327 364 683 207 593  55 565 190  81 314 180\n",
      "  51  15 438 186 249  87 310 103 144 542 183   3 393 202 428 690 367 274\n",
      " 516 348 686 153  76  64 140 659 528  67 382 408  90 572 126 344 460 280\n",
      " 585  34 252 635  48 477 425 461 584 152 406 161 570 278  22 365 474 214\n",
      " 688 631  45  77 491 170 340 682 345  66 620  44 283 476 339 538  37 637\n",
      " 475 184 163 173 330 431 377 376 378 607 235 539 673 169 618 654  52  58\n",
      " 421 129 644  70  19 123 646 301 483 638 552 503 526 481  11  63 251 220\n",
      " 309 200 458  12  41 222 504 119 487 104 509 465 603 379 232 223 691 643\n",
      " 623 114 601 298 117 143 369 297 139  73 208 604 262 392 419 171 444 270\n",
      " 557 567 501 473 387 122 305 448 198  46 543 150  60 529 577 619 234 427\n",
      " 571  97 633 146 515 558 381 400 337  86 138 266 605 629 533 221  30 399\n",
      " 275  57 482 662 133 551 225 347 316 488 407 496 193 411]\n",
      "TEST: [414 242 628  94 450 630 409 355 206 521  54 363  71 394 588 224 608  32\n",
      " 105 188 464 451 568 175 332 128 333 679 596 500 426  69 320 405 213 196\n",
      "  89 229 443 257 692  42 238 401  65  92 652 530  18 289  39 125 639  49\n",
      "  82 518 415 651 380 375 472  35 349  24 670 286 397 386 106 495 307 343\n",
      "  59 513 204 610 361 625  36 260 615 308   4 479  78 131 269 195 550 502\n",
      " 145 507 462   1 212 182 276 209 449 650 432 113 178 520 217 338 560 254\n",
      " 291 258  31 423  91 434 663 446 404 176 614 132 385 412 435  61 564 322\n",
      " 312 546  20 658 649 547 562  43 447 374  75 263 323]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       0.33      1.00      0.50         1\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       0.50      1.00      0.67         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       0.67      1.00      0.80         2\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      0.50      0.67         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       0.67      1.00      0.80         2\n",
      "         20       0.67      1.00      0.80         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       0.67      1.00      0.80         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       1.00      0.50      0.67         2\n",
      "         28       1.00      0.50      0.67         2\n",
      "         29       0.00      0.00      0.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       0.67      1.00      0.80         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      0.50      0.67         2\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       0.50      1.00      0.67         1\n",
      "         42       0.50      1.00      0.67         1\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      0.50      0.67         2\n",
      "         47       1.00      0.50      0.67         2\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       0.00      0.00      0.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         2\n",
      "         54       1.00      0.50      0.67         2\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       0.50      1.00      0.67         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         2\n",
      "         59       0.50      1.00      0.67         1\n",
      "         60       0.50      1.00      0.67         1\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       0.50      1.00      0.67         1\n",
      "         63       0.00      0.00      0.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       0.50      0.50      0.50         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         2\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       0.33      0.50      0.40         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      0.50      0.67         2\n",
      "         76       0.00      0.00      0.00         1\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         2\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       1.00      0.50      0.67         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       0.50      1.00      0.67         1\n",
      "         91       1.00      1.00      1.00         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.87      0.86      0.85       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  4  #################\n",
      "TRAIN: [675 565 152 353 421 197 636 603  87 461  30 618   8 648 574 610 480 456\n",
      " 336  69 174 397 474 593 154  65 366  75 364 370 427 566 130 285 165 157\n",
      " 128 307 546 575 327 586 595  22   0 263 293 365 626 633 689 249  91 252\n",
      " 584 513 451 512 499   4 429 594  18 189 117 377 188 649 475  20 406 283\n",
      " 166  80 303 289 612 494 578 290 426 308  83 349 522 271  31 401 106 616\n",
      " 342 236 304 537 344 331 350 501 180  11 473 118 445 235 452 641 297  29\n",
      " 149 228 600 301  25 464 465 382 394 169 121 495 409  90  36 569 182 193\n",
      " 433 332  23  17 459 638 400 558  63 446 122 348 601  79   9 453  44 323\n",
      "  52  78  53 330 550 620 138 422 470 570  43 210 258 316 653 352 218  89\n",
      " 102 309 229 343 201 617 450 527 291 164 241 268 104  41 443 259 296 376\n",
      " 265 351 628 248 652 367  49 685 692 372 621 209 126 255 112 256 211 194\n",
      "  57 449 681 124 554 135   7 548 318 544 357 536 587 281 662  39 644 375\n",
      " 225 563 509 679 176 205 321  12 374 659 686 542  13 538 651 156  88 555\n",
      " 642  74 471 386 171 254  76  77 657 466 299 129 387  92 585  14 609 359\n",
      "  67 655 161 275 277 287 334 431 607 360 656 412  62 260 444 545  64 571\n",
      "  27 658 362  84 200 381 643 533 581  38 125 310 108  33 496 403 322 619\n",
      " 177 635 369 517  51 140 526  98 623 146 492 481 300 691  73 559 212 434\n",
      "  16 442 105 245 458 670 487 405 145 669 345 136 312  55 407 113 227 319\n",
      " 676 363 417 438 385 196 514 160 216 608  48 435 523 410 645 439 181 392\n",
      " 605  42 111 173 502 162 543 528 354 625 142 511 667 419 415 541 398 192\n",
      " 428 440 614 288 141 355 432 673 455 346 560 687 395  46 567 361 577 131\n",
      "  72  45 101 150 278 665 404 306 213 632 204 491 317 463 313 191 425 358\n",
      " 524 627 572 175 503  32 294 120 168 274  47 199 239 371 672  60 423 272\n",
      " 500 378 525 311 411 273 148 424 207 186 389 116 231 163 518 280 267 552\n",
      " 436 688 674 333 457  81  15 279 183 519 484 420 264 233 257 396  86 447\n",
      "  82   5  61 276 143  70 110 479 380 324 504 222 582 179 244 490 597 682\n",
      "  93   3 684 198 109  28 485 144 556 634 221 114   1 611 647 373 103  50\n",
      " 615 390 214 654 557 282 505 547 251 226 388 266 598  35 270 671 413 408\n",
      " 529 123 224 553 178  95 339  94 230 347 478 379 588 337 220 340 437 483\n",
      " 416 247  10 243 246 187  37 391 540 185 100 320 535 329 506 119 132 184\n",
      " 590 521 631 680 315 356 606 383 202 325 139 305 206 127]\n",
      "TEST: [242 153 579 147 482 666 460 510 531 115 215  56 219 468 441 137 190 208\n",
      " 167  54 134 568 107 629  66 462 250 472 646 664 589 151 170 591 592 489\n",
      " 668 530 497 234 596 551 195 295 302 640 488 549 561 580 269 630 520 172\n",
      " 562   2  19 286 253  71 298 158 583 573 507 326 328  34 599 467  26 539\n",
      " 203 238  24 622 284 576 661   6 262 399 338 418 414  21 639 602 476 660\n",
      "  85 477 486 690 663 613 604 448 232 532  99 564 677 384 240 469 292 534\n",
      " 678 314 368 650 516 683 341 637 454 237 223 430  96 159 508 335 261 217\n",
      "  97  58 155  40 133  59 624 498 493 393 515 402  68]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       0.33      1.00      0.50         1\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       0.50      1.00      0.67         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       0.50      1.00      0.67         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       0.50      1.00      0.67         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      0.50      0.67         2\n",
      "         14       0.67      1.00      0.80         2\n",
      "         15       0.33      1.00      0.50         1\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      0.50      0.67         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       1.00      0.50      0.67         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       1.00      0.50      0.67         2\n",
      "         29       1.00      1.00      1.00         2\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       0.50      1.00      0.67         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       0.50      1.00      0.67         1\n",
      "         35       1.00      0.50      0.67         2\n",
      "         36       0.00      0.00      0.00         1\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         1\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       0.67      1.00      0.80         2\n",
      "         51       0.00      0.00      0.00         1\n",
      "         52       0.50      1.00      0.67         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       0.50      1.00      0.67         1\n",
      "         56       0.50      1.00      0.67         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       1.00      0.50      0.67         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       0.00      0.00      0.00         1\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      0.50      0.67         2\n",
      "         70       0.67      1.00      0.80         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      0.50      0.67         2\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       0.50      1.00      0.67         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      0.50      0.67         2\n",
      "         85       1.00      1.00      1.00         2\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      0.50      0.67         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       0.50      1.00      0.67         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       0.67      1.00      0.80         2\n",
      "         93       1.00      0.50      0.67         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       0.50      1.00      0.67         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      0.50      0.67         2\n",
      "\n",
      "avg / total       0.87      0.85      0.83       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 137   0\n",
       "   N   0   2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.5,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0145985401459854,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9856115107913669,\n",
      "    'Rate of positive predictions': 0.9856115107913669,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  5  #################\n",
      "TRAIN: [556 165  54 370 309 193 269 229 491  59 492 565 362 418 612 128 606 149\n",
      " 422  98 241 381 304 635 604 336 654 261 355 231 187 200 475 199 463 522\n",
      "  49 639 472 649 120 508 480 420 670 296  73  94 108 212 435 392 317  63\n",
      " 308 663  83 145 218 223 593 653  62 268 678 243 146 470   2 102 173 235\n",
      " 679 281 582   7   5 575 270 148 385 485 659  65  95 421 150 303 484 330\n",
      "  96 374 397  22 517 578 618 251 534 464 162  80  21   6 380 400 561  52\n",
      " 544 538  61 401 278 550 154 334   0 673 191 127 572 230 256 142 629 121\n",
      " 430 252 341 225   9 131 531 425  48 141 207 176 255  41 410 373 454 215\n",
      " 633 224 617 376 195 101 242  10 417 349  75 153 332 540 358 494 286 487\n",
      " 601  33 610 329 394 169  32  53  97 597 434 583  35 357 289 112 322 406\n",
      " 548 436 448   3 151  68 579 626 284 384 688 213 509 369  86 478  84 490\n",
      " 361 545 320 371  24 574 432  71 685 192 458 613 294 553 117 249  42 446\n",
      " 404 290  55 433 291 305 277 378 280 262 640  56 253  79 363 462 178 163\n",
      " 377 523 431 236  82 690 468  99 558 315 155 573 596 311 569 398 393 202\n",
      " 266   8 209 520 450 622 403 474 476 135 681 125 528 619 563 570 605 647\n",
      " 632 671 429 246   1 160 143 318  45 396  19 204 107 293 354 222  40  87\n",
      " 300 598  34   4 510 372 625 189 588 552  93  69  50 683 161  31  91 519\n",
      " 658 323 196 333 411 516 201 650  57 496 486 527 460 167 656  66 682 170\n",
      " 382 287 525 264 226 676 174 655 636 592 567 316 680 405 171 689 182 466\n",
      " 437 118 481 345 144 389 489 521 352 473 488 221 383 185 591 438 628 183\n",
      " 402  58 513 652 214 325 576 177 340 506 335 667 147 298 134 511 452  76\n",
      " 122 589 638 217 611  43 560 267 307 138 512  25  74 453 301 203  37 186\n",
      " 282  16  36 530 238  29 337 559  90 424  17 328 367 661 660 164 119 419\n",
      " 599 637 132 387 562 498 467 455 537 136 220  46 351  12 643 529 541  14\n",
      " 482 532 179 152 276 365 590 339 391  30 245 273  81  23  89 181 233 662\n",
      " 190 299 368 465 324  18 237 240 443 110 197 686 668 664  92 426 313 338\n",
      " 271 580 439  15 312 227  39 263 103 156 295 188 416 168 423 500 205  38\n",
      " 247 123 551 595 571 547 524 445 360 507  67 275  72 447 210 440 444 140\n",
      " 514 675 413 302 586 175 594 505 364 228 457  28 581 539 456 265 137 657\n",
      " 342 115  11 166 194 319 669 543 584 388  88 133 642 607 677 620 344 615\n",
      " 614 100 461 648 158 409 350 379 327 285 666 343 274 546]\n",
      "TEST: [ 60 310 124 427 630 180 549 111 483 139 542 321 346 631 106 515 347 260\n",
      " 623 250 258 587 244 624 331 105 535 172 297 159 109 257 602 557 412 198\n",
      " 415  13 503 501 130 356 326  26 634 407 459 554 609 672 219 471 684 651\n",
      " 641 451 603 254 518 414 449 600  70 279  44 526 113 441 116 129 442 585\n",
      " 479 353  51  20 184 577 428 248 208 502 395 314  47 627 104 211 386 114\n",
      "  78 292 674 497 692 272 234 359 239  85 477 533 232  27 621 568  77 564\n",
      " 665 646 504 555 608  64 288 536 691 157 495 645 216 206 566 126 493 259\n",
      " 616 469 366 348 375 408 306 399 390 687 644 283 499]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       0.67      1.00      0.80         2\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         2\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      0.50      0.67         2\n",
      "         12       0.50      1.00      0.67         1\n",
      "         13       0.50      1.00      0.67         1\n",
      "         14       1.00      1.00      1.00         2\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       0.50      1.00      0.67         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      0.50      0.67         2\n",
      "         23       0.50      1.00      0.67         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      0.50      0.67         2\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       1.00      0.50      0.67         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       0.33      1.00      0.50         1\n",
      "         32       0.50      0.50      0.50         2\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       0.33      1.00      0.50         1\n",
      "         35       1.00      0.50      0.67         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      0.50      0.67         2\n",
      "         41       1.00      1.00      1.00         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       0.00      0.00      0.00         1\n",
      "         44       0.67      1.00      0.80         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         2\n",
      "         50       0.00      0.00      0.00         1\n",
      "         51       1.00      1.00      1.00         2\n",
      "         52       0.50      1.00      0.67         2\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       0.50      1.00      0.67         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       0.67      1.00      0.80         2\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       0.50      0.50      0.50         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      0.50      0.67         2\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       0.00      0.00      0.00         1\n",
      "         66       0.50      0.50      0.50         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       0.00      0.00      0.00         1\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       1.00      1.00      1.00         1\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       0.50      1.00      0.67         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       0.50      0.50      0.50         2\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       0.00      0.00      0.00         2\n",
      "         80       1.00      1.00      1.00         1\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      0.50      0.67         2\n",
      "         86       1.00      1.00      1.00         2\n",
      "         87       1.00      0.50      0.67         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      0.50      0.67         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         2\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.85      0.83      0.82       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 25.5,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Validation #################\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.67      0.57         3\n",
      "          1       0.60      1.00      0.75         3\n",
      "          2       0.60      1.00      0.75         3\n",
      "          3       0.75      1.00      0.86         3\n",
      "          4       0.60      1.00      0.75         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       0.75      1.00      0.86         3\n",
      "          7       0.60      1.00      0.75         3\n",
      "          8       0.75      1.00      0.86         3\n",
      "          9       1.00      1.00      1.00         3\n",
      "         10       0.60      1.00      0.75         3\n",
      "         11       1.00      0.67      0.80         3\n",
      "         12       0.75      1.00      0.86         3\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       1.00      1.00      1.00         3\n",
      "         15       0.75      1.00      0.86         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      0.33      0.50         3\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.50      0.33      0.40         3\n",
      "         21       0.75      1.00      0.86         3\n",
      "         22       0.50      1.00      0.67         3\n",
      "         23       1.00      0.33      0.50         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       0.75      1.00      0.86         3\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       0.60      1.00      0.75         3\n",
      "         28       1.00      0.67      0.80         3\n",
      "         29       1.00      0.67      0.80         3\n",
      "         30       1.00      1.00      1.00         3\n",
      "         31       1.00      0.67      0.80         3\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         3\n",
      "         34       1.00      1.00      1.00         3\n",
      "         35       1.00      0.67      0.80         3\n",
      "         36       1.00      0.67      0.80         3\n",
      "         37       1.00      0.67      0.80         3\n",
      "         38       0.75      1.00      0.86         3\n",
      "         39       0.75      1.00      0.86         3\n",
      "         40       1.00      0.67      0.80         3\n",
      "         41       1.00      0.33      0.50         3\n",
      "         42       1.00      1.00      1.00         3\n",
      "         43       1.00      1.00      1.00         3\n",
      "         44       0.67      0.67      0.67         3\n",
      "         45       1.00      0.67      0.80         3\n",
      "         46       1.00      1.00      1.00         3\n",
      "         47       1.00      1.00      1.00         3\n",
      "         48       1.00      0.33      0.50         3\n",
      "         49       1.00      0.33      0.50         3\n",
      "         50       1.00      0.67      0.80         3\n",
      "         51       1.00      1.00      1.00         3\n",
      "         52       0.75      1.00      0.86         3\n",
      "         53       0.75      1.00      0.86         3\n",
      "         54       0.60      1.00      0.75         3\n",
      "         55       0.67      0.67      0.67         3\n",
      "         56       1.00      1.00      1.00         3\n",
      "         57       1.00      1.00      1.00         3\n",
      "         58       0.75      1.00      0.86         3\n",
      "         59       0.75      1.00      0.86         3\n",
      "         60       0.75      1.00      0.86         3\n",
      "         61       0.75      1.00      0.86         3\n",
      "         62       1.00      1.00      1.00         3\n",
      "         63       0.75      1.00      0.86         3\n",
      "         64       1.00      0.67      0.80         3\n",
      "         65       0.67      0.67      0.67         3\n",
      "         66       0.50      0.67      0.57         3\n",
      "         67       1.00      1.00      1.00         3\n",
      "         68       1.00      0.33      0.50         3\n",
      "         69       0.50      0.67      0.57         3\n",
      "         70       1.00      1.00      1.00         3\n",
      "         71       1.00      0.67      0.80         3\n",
      "         72       1.00      1.00      1.00         3\n",
      "         73       0.50      0.33      0.40         3\n",
      "         74       1.00      1.00      1.00         3\n",
      "         75       1.00      0.67      0.80         3\n",
      "         76       0.75      1.00      0.86         3\n",
      "         77       1.00      1.00      1.00         3\n",
      "         78       1.00      1.00      1.00         3\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       1.00      0.67      0.80         3\n",
      "         81       1.00      1.00      1.00         3\n",
      "         82       1.00      0.67      0.80         3\n",
      "         83       1.00      0.67      0.80         3\n",
      "         84       1.00      1.00      1.00         3\n",
      "         85       1.00      0.67      0.80         3\n",
      "         86       0.25      0.33      0.29         3\n",
      "         87       1.00      0.33      0.50         3\n",
      "         88       0.75      1.00      0.86         3\n",
      "         89       1.00      1.00      1.00         3\n",
      "         90       0.00      0.00      0.00         3\n",
      "         91       1.00      1.00      1.00         3\n",
      "         92       1.00      0.67      0.80         3\n",
      "         93       0.75      1.00      0.86         3\n",
      "         94       0.75      1.00      0.86         3\n",
      "         95       1.00      0.67      0.80         3\n",
      "         96       1.00      1.00      1.00         3\n",
      "         97       1.00      0.33      0.50         3\n",
      "         98       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.86      0.83      0.82       297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 292   2\n",
       "   N   1   2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.6666666666666667,\n",
      "    'Accuracy': 0.98989898989899,\n",
      "    'Error rate': 0.010101010101010102,\n",
      "    'False negative rate': 0.006802721088435374,\n",
      "    'False positive rate': 0.3333333333333333,\n",
      "    'Lift value': 1.0067562861322004,\n",
      "    'Precision J': 0.9965870307167235,\n",
      "    'Precision N': 0.5,\n",
      "    'Rate of negative predictions': 0.98989898989899,\n",
      "    'Rate of positive predictions': 0.9865319865319865,\n",
      "    'Sensitivity (true positives rate)': 0.9931972789115646,\n",
      "    'Specificity (true negatives rate)': 0.6666666666666666,\n",
      "    'f1_R': 0.5714285714285715,\n",
      "    'kappa': 0.5664233576642341}\n",
      "###################### Training Fold:  1  #################\n",
      "TRAIN: [259  47  82 636  26 214 403  90 233 238 548 545 110 107 602 480 489 577\n",
      "  76 404 285 437 321  19  49 376  94 179 339 184 518 278 477 302 616 325\n",
      " 269 505 597 328 303 108 315 239 603 375  23 447 443 247 438 526 287 389\n",
      " 473 309 654  53 326 401 406 614 360 103 204 691 161 196 413   2 252 296\n",
      " 139 546 352 164 222 255 588 445 240 387  61 324 400 642 689 384 685 386\n",
      " 385 142 610 573 323 116 237 688  13 529  12 193  38  21 618 169 576 319\n",
      " 419 200   1 536 390 498 405 591 253 106 297 595 146 645 230 551 686 510\n",
      " 417 305 635 147 673 219 207 580 589 647 598 145 575 683 436 607 687 463\n",
      " 335  98 590 348 371 260 366 102 329 659 538 478  68 135 332 535 649 216\n",
      " 118 148 249 264 513 220 350 630 322  22 481 410 679 664 369  67 359 173\n",
      " 676 677 364 560 458 640 428 354 308  25  99 265 425 583 675 578 631  40\n",
      " 609 572 275  42 327 137 494 474 632 236 104 316 355  74 562 493  96 351\n",
      " 579 454 221 225 215 550 430 307 243 509 465 623  29 434 246  70 248 564\n",
      " 188  43 584 121 619 592 279 626 429 358 310 461 608  51 158 251 210 208\n",
      " 521 337  18 189   3  87 605 198  45 657 557 144 462 128 368 650 585 422\n",
      " 668 639 467 166 136 431 561 581 268 213   7  48 460 459 342 484 133 163\n",
      " 625 276 427  66 289 500 211 205  84 171 490  85 541 441 228 370 520 217\n",
      "  33 658  71 497 101 112 209 257 690 270 661 154 274 178 168  11 183 180\n",
      "  36 442  54 582 641 331 418   4 301 120 347 516 411 453 123 314 398  20\n",
      " 680 338 267 671 363 499 244 292 254 399  60 201 129 311 586 555 334 306\n",
      "  41 446 122 496 312 195 113 132 486  28  39 402  83 552 667 502 457  31\n",
      " 504 432  37 124 416 141 258 559 440 522 320 483 570 670 318 615 512  81\n",
      " 622  91 345 190  73 503  14 469 563 448 397 666 515 256 476 382 556 170\n",
      " 524 672  30 565 153 596 415 391 280 553 151 381 523 160 420 606 261 177\n",
      " 333 250  15 451 514 388  80 293 298 525 374  16 452 519 140 628 466 235\n",
      " 234 115 199 353 127 629 611 242 284 681 542 472 554  44 627 421 669  86\n",
      " 537   6  58 282 624 435 464 149 223 507  46 485 471 343 152 232 587 372\n",
      " 143 373  95 150 468 612 245 684 449 186 156 271 291 633 648 336  17 362\n",
      "  63  75 495 674  24 450 660 229 692 218 356 534  55 288 568 299 617 277\n",
      "  62 126 346 224 549  34 662 138 599 424 377 527 656 130 558 172 175 569\n",
      " 479 407 367 604 165 528 341  93 176 157 203 117 531 530]\n",
      "TEST: [621  52 349 634 286 294 600 379   9 655 185 131  69 506 281  59 492 539\n",
      " 226 361 393 159 197 273 533 456 272 517 304  10 111 601 544 182 194 383\n",
      " 665 392 357 174 511 652 547  88  78 192 105  77 653 365  27 423 433  50\n",
      "  57 426 482 340 283 414 593 439 501 409 119 181  35 643 162 444 571 290\n",
      " 644 227 637 470 395 620 206   5 594 125 167 663  92 155 114 613 241 567\n",
      " 638 263 566 678 212 330 488  89 412 109 191 396 646 540 532  64 682  72\n",
      " 491 187 380 134 408 378 317 344 394 475  65 651   0 266 574  32 313 262\n",
      " 202 300  56 100  79   8 487 455 543 508  97 295 231]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       0.67      1.00      0.80         2\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       0.50      0.50      0.50         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         2\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      0.50      0.67         2\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         2\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         2\n",
      "         56       0.50      1.00      0.67         1\n",
      "         57       1.00      1.00      1.00         2\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         2\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       0.50      1.00      0.67         2\n",
      "         72       1.00      1.00      1.00         2\n",
      "         73       1.00      1.00      1.00         2\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         1\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      1.00      1.00         2\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      0.50      0.67         2\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         2\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         2\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.96      0.96      0.95       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  2  #################\n",
      "TRAIN: [ 60 545 625 533  59 355 423 159 223 577 576 688  95 510 397 572  31 135\n",
      " 569 131 132 670 518  24 101 403 421 580 202 118   8 324 493 316  28 386\n",
      " 331 283 342 557 371 548 608 246  26 477 140 327 547 542 116 393 516 687\n",
      " 419 384 514 619 685 320 626 263 230 220 537 663   3 359 609  61 178 473\n",
      " 275 165 413 366 242 334 241 388 245 554 189 385 147 161 254 375 104 219\n",
      " 322 158 156 229 314 185 534 471 170 374 236 679 148 425 635 402 370 566\n",
      " 134 206 458 109 672 201  14 112   6 631 356 108 553 440 442 650 532 523\n",
      " 240  78 428  65 596  68 188 522 344 529  15 507 164 309 207 111  62  47\n",
      " 225 456 676  79 346 265 612 204 372 573 315  46 610 298 466 658 279 262\n",
      " 336 556  45 352 292 330 427  92 335  20 377 105 227 571 150  77 253 239\n",
      " 416 486 152 361  97 287 200 648 181 209 605 248  16 485  90 464 463 321\n",
      "  44 653 490 291 226 367 409 351  22 126 447 468 628  23 302 614 677  70\n",
      " 203 494 461  98 412 382 600  89 141  48 599 592 435 482 681 665 686 368\n",
      " 607 271 338 124 536 399 329 660 296 535 669 347 299 520  17 127 401 583\n",
      " 266  30 594 396 100   5 357 293 429 255 137 678 661 638 110 656 551  32\n",
      " 671 662  36 667  84 527 167 570   9  11 373 192 268 378  21 325  71 153\n",
      " 142 125 515 474 475  88 213 211 252 593 323 417 459  85 630 273  49  34\n",
      " 197 251 146 564 308  43  27 647 117 404 179 524 106 622 243 654 567 505\n",
      " 651 363 272 615 233 457 139 469 546  58 646  52  82 684 284 163 232 604\n",
      " 280 247 629 389 636 343  81  25 295 282 176 645 184 180 205 301 381 496\n",
      " 528 666 640 438 526  80 632 174 587 129 103 581 519 151 391 261 194 306\n",
      " 414 613 540 358  94 387 171 216 281 168 437 237 285 379 649  96 568 531\n",
      "  73 395 655 328 310 289 467 563  67 668 269 208 274 392 465 480 345 339\n",
      " 349 543 256 470  13 113 606 492 598  86 498 138 657 380 495 445 133 588\n",
      "  64 286  53 362 578  41 595   7 664 452 639 579 460 172 259 508 405 186\n",
      " 673 430 513 652 191 487 506 297 511 276 637 503 530 597 177 602 642 154\n",
      " 446 582 173 434 144 122 476 128 221 558 199  40 149 586 365 411 311 319\n",
      " 589 250 674   0 267 305 680 210 683 394 478 364 264  56 549 552 538 340\n",
      " 644 317 341 488 257 472  69 618 258 449 483 585 584 641 621  38 212 634\n",
      " 623 214 541 182  87 198 611 155 224 443 406  83 410 432  12 555 120  50\n",
      "  37 217 190 222 484 659 290  18  57 294 517  93 574  39]\n",
      "TEST: [560 633 196 682 499  99  63 624   4  72 383 575 145 115 479 376 193 455\n",
      " 603 157  74 422 162 565 502 119 260 509 143 195 307 183 512 400 121  29\n",
      " 408 433 692 249  66 544 561  51 114 617 444 616 441  54 107 675 431  91\n",
      " 350 420 453 500 278 643 539  33 439 559 691 244 228 489  10 407   2  35\n",
      " 450  55 231 426   1 169  19 497 313 601 166 690 360 415 348 451 521 454\n",
      " 504 187 218 123 369 525 130 160 288 332  42 175 501 238  75 354 300 326\n",
      " 448 318 215 102 390 136 562 424 418 303 333 627 337 353 462 491 689 270\n",
      " 590 620 481  76 304 398 436 312 234 550 277 235 591]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         2\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       0.50      1.00      0.67         1\n",
      "         29       1.00      0.50      0.67         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         2\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         1\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         2\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         2\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         2\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      0.50      0.67         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         2\n",
      "         84       1.00      1.00      1.00         2\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       0.50      1.00      0.67         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         2\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.99      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  3  #################\n",
      "TRAIN: [303 265 624 674 245 237 318  95 326 185 684 194 594 430 389 156 466 181\n",
      " 532 440 545 484 372 396 319 304 288  93 508 554 480  53 541 160 147 201\n",
      "   7 282 671 112 353 313 685 277 455 118 115 366  14 370 168 576 240 321\n",
      " 100 457 272 470 563 512 391 469 641 433 505  83 511   5 598 579 578 485\n",
      " 179 510 187 445 335 311 121 424 681 535 668  85 141 442 346 395 174 154\n",
      " 622  21 359 356 306 124 271 300 384  28 127 233  27  56 244 342 294 247\n",
      " 489 191 157 661 580 189 268 279 357 524 553 677 534 439 199 566 574 648\n",
      " 162 586  47 527 299 295  29 497  38 522 315 134 205 453   2 352 226 669\n",
      " 537 239  74  84 167 613 248 130 341   9 290 230 241 166 436 149 418  98\n",
      " 324 452 689 549 110 544 498  79 273 256 642 657 583 155 362 413 672 556\n",
      " 336 555 645 634 109 292 612 582 519  25 478 246 429 591 293 210  88 640\n",
      " 231 264 656 653 261 600 621 219 632 597  26 285 437 255 158 302  17 172\n",
      " 216 493   8 678  99 595 540 459 548 159 287 609 142 523 388 468 416 655\n",
      " 354  68 373   6  16 680 573 676 441 517 317 463 471 664 111 203 136 536\n",
      " 325 368 587 581 456  10 514  23 606 351 575 107 611 284 164 120  13 490\n",
      " 108 410  40 102 647 329 137 636 506 350 492 281 253 197  50 165 660 259\n",
      " 267 467 531 486 398 371 675 177 358 667 617  72 589 116 687 665 525  96\n",
      " 228 148 599 559 192 666 499 592 417 626 561 420  80 569 250 151 454 590\n",
      " 101 390 236 243   0 360 296  33 215 494 334 331 602 383 328 227 627  62\n",
      " 218 135 616 402 422 211 403 327 364 683 207 593  55 565 190  81 314 180\n",
      "  51  15 438 186 249  87 310 103 144 542 183   3 393 202 428 690 367 274\n",
      " 516 348 686 153  76  64 140 659 528  67 382 408  90 572 126 344 460 280\n",
      " 585  34 252 635  48 477 425 461 584 152 406 161 570 278  22 365 474 214\n",
      " 688 631  45  77 491 170 340 682 345  66 620  44 283 476 339 538  37 637\n",
      " 475 184 163 173 330 431 377 376 378 607 235 539 673 169 618 654  52  58\n",
      " 421 129 644  70  19 123 646 301 483 638 552 503 526 481  11  63 251 220\n",
      " 309 200 458  12  41 222 504 119 487 104 509 465 603 379 232 223 691 643\n",
      " 623 114 601 298 117 143 369 297 139  73 208 604 262 392 419 171 444 270\n",
      " 557 567 501 473 387 122 305 448 198  46 543 150  60 529 577 619 234 427\n",
      " 571  97 633 146 515 558 381 400 337  86 138 266 605 629 533 221  30 399\n",
      " 275  57 482 662 133 551 225 347 316 488 407 496 193 411]\n",
      "TEST: [414 242 628  94 450 630 409 355 206 521  54 363  71 394 588 224 608  32\n",
      " 105 188 464 451 568 175 332 128 333 679 596 500 426  69 320 405 213 196\n",
      "  89 229 443 257 692  42 238 401  65  92 652 530  18 289  39 125 639  49\n",
      "  82 518 415 651 380 375 472  35 349  24 670 286 397 386 106 495 307 343\n",
      "  59 513 204 610 361 625  36 260 615 308   4 479  78 131 269 195 550 502\n",
      " 145 507 462   1 212 182 276 209 449 650 432 113 178 520 217 338 560 254\n",
      " 291 258  31 423  91 434 663 446 404 176 614 132 385 412 435  61 564 322\n",
      " 312 546  20 658 649 547 562  43 447 374  75 263 323]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         2\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         2\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      1.00      1.00         2\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         1\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         2\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      0.50      0.67         2\n",
      "         54       1.00      1.00      1.00         2\n",
      "         55       0.50      1.00      0.67         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         2\n",
      "         59       1.00      1.00      1.00         1\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         2\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         2\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      1.00      1.00         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  4  #################\n",
      "TRAIN: [675 565 152 353 421 197 636 603  87 461  30 618   8 648 574 610 480 456\n",
      " 336  69 174 397 474 593 154  65 366  75 364 370 427 566 130 285 165 157\n",
      " 128 307 546 575 327 586 595  22   0 263 293 365 626 633 689 249  91 252\n",
      " 584 513 451 512 499   4 429 594  18 189 117 377 188 649 475  20 406 283\n",
      " 166  80 303 289 612 494 578 290 426 308  83 349 522 271  31 401 106 616\n",
      " 342 236 304 537 344 331 350 501 180  11 473 118 445 235 452 641 297  29\n",
      " 149 228 600 301  25 464 465 382 394 169 121 495 409  90  36 569 182 193\n",
      " 433 332  23  17 459 638 400 558  63 446 122 348 601  79   9 453  44 323\n",
      "  52  78  53 330 550 620 138 422 470 570  43 210 258 316 653 352 218  89\n",
      " 102 309 229 343 201 617 450 527 291 164 241 268 104  41 443 259 296 376\n",
      " 265 351 628 248 652 367  49 685 692 372 621 209 126 255 112 256 211 194\n",
      "  57 449 681 124 554 135   7 548 318 544 357 536 587 281 662  39 644 375\n",
      " 225 563 509 679 176 205 321  12 374 659 686 542  13 538 651 156  88 555\n",
      " 642  74 471 386 171 254  76  77 657 466 299 129 387  92 585  14 609 359\n",
      "  67 655 161 275 277 287 334 431 607 360 656 412  62 260 444 545  64 571\n",
      "  27 658 362  84 200 381 643 533 581  38 125 310 108  33 496 403 322 619\n",
      " 177 635 369 517  51 140 526  98 623 146 492 481 300 691  73 559 212 434\n",
      "  16 442 105 245 458 670 487 405 145 669 345 136 312  55 407 113 227 319\n",
      " 676 363 417 438 385 196 514 160 216 608  48 435 523 410 645 439 181 392\n",
      " 605  42 111 173 502 162 543 528 354 625 142 511 667 419 415 541 398 192\n",
      " 428 440 614 288 141 355 432 673 455 346 560 687 395  46 567 361 577 131\n",
      "  72  45 101 150 278 665 404 306 213 632 204 491 317 463 313 191 425 358\n",
      " 524 627 572 175 503  32 294 120 168 274  47 199 239 371 672  60 423 272\n",
      " 500 378 525 311 411 273 148 424 207 186 389 116 231 163 518 280 267 552\n",
      " 436 688 674 333 457  81  15 279 183 519 484 420 264 233 257 396  86 447\n",
      "  82   5  61 276 143  70 110 479 380 324 504 222 582 179 244 490 597 682\n",
      "  93   3 684 198 109  28 485 144 556 634 221 114   1 611 647 373 103  50\n",
      " 615 390 214 654 557 282 505 547 251 226 388 266 598  35 270 671 413 408\n",
      " 529 123 224 553 178  95 339  94 230 347 478 379 588 337 220 340 437 483\n",
      " 416 247  10 243 246 187  37 391 540 185 100 320 535 329 506 119 132 184\n",
      " 590 521 631 680 315 356 606 383 202 325 139 305 206 127]\n",
      "TEST: [242 153 579 147 482 666 460 510 531 115 215  56 219 468 441 137 190 208\n",
      " 167  54 134 568 107 629  66 462 250 472 646 664 589 151 170 591 592 489\n",
      " 668 530 497 234 596 551 195 295 302 640 488 549 561 580 269 630 520 172\n",
      " 562   2  19 286 253  71 298 158 583 573 507 326 328  34 599 467  26 539\n",
      " 203 238  24 622 284 576 661   6 262 399 338 418 414  21 639 602 476 660\n",
      "  85 477 486 690 663 613 604 448 232 532  99 564 677 384 240 469 292 534\n",
      " 678 314 368 650 516 683 341 637 454 237 223 430  96 159 508 335 261 217\n",
      "  97  58 155  40 133  59 624 498 493 393 515 402  68]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         2\n",
      "         14       1.00      1.00      1.00         2\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       1.00      1.00      1.00         2\n",
      "         29       1.00      1.00      1.00         2\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       0.50      1.00      0.67         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         1\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         2\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      0.50      0.67         2\n",
      "         85       1.00      1.00      1.00         2\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      1.00      1.00         2\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 137   0\n",
       "   N   0   2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0145985401459854,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9856115107913669,\n",
      "    'Rate of positive predictions': 0.9856115107913669,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  5  #################\n",
      "TRAIN: [556 165  54 370 309 193 269 229 491  59 492 565 362 418 612 128 606 149\n",
      " 422  98 241 381 304 635 604 336 654 261 355 231 187 200 475 199 463 522\n",
      "  49 639 472 649 120 508 480 420 670 296  73  94 108 212 435 392 317  63\n",
      " 308 663  83 145 218 223 593 653  62 268 678 243 146 470   2 102 173 235\n",
      " 679 281 582   7   5 575 270 148 385 485 659  65  95 421 150 303 484 330\n",
      "  96 374 397  22 517 578 618 251 534 464 162  80  21   6 380 400 561  52\n",
      " 544 538  61 401 278 550 154 334   0 673 191 127 572 230 256 142 629 121\n",
      " 430 252 341 225   9 131 531 425  48 141 207 176 255  41 410 373 454 215\n",
      " 633 224 617 376 195 101 242  10 417 349  75 153 332 540 358 494 286 487\n",
      " 601  33 610 329 394 169  32  53  97 597 434 583  35 357 289 112 322 406\n",
      " 548 436 448   3 151  68 579 626 284 384 688 213 509 369  86 478  84 490\n",
      " 361 545 320 371  24 574 432  71 685 192 458 613 294 553 117 249  42 446\n",
      " 404 290  55 433 291 305 277 378 280 262 640  56 253  79 363 462 178 163\n",
      " 377 523 431 236  82 690 468  99 558 315 155 573 596 311 569 398 393 202\n",
      " 266   8 209 520 450 622 403 474 476 135 681 125 528 619 563 570 605 647\n",
      " 632 671 429 246   1 160 143 318  45 396  19 204 107 293 354 222  40  87\n",
      " 300 598  34   4 510 372 625 189 588 552  93  69  50 683 161  31  91 519\n",
      " 658 323 196 333 411 516 201 650  57 496 486 527 460 167 656  66 682 170\n",
      " 382 287 525 264 226 676 174 655 636 592 567 316 680 405 171 689 182 466\n",
      " 437 118 481 345 144 389 489 521 352 473 488 221 383 185 591 438 628 183\n",
      " 402  58 513 652 214 325 576 177 340 506 335 667 147 298 134 511 452  76\n",
      " 122 589 638 217 611  43 560 267 307 138 512  25  74 453 301 203  37 186\n",
      " 282  16  36 530 238  29 337 559  90 424  17 328 367 661 660 164 119 419\n",
      " 599 637 132 387 562 498 467 455 537 136 220  46 351  12 643 529 541  14\n",
      " 482 532 179 152 276 365 590 339 391  30 245 273  81  23  89 181 233 662\n",
      " 190 299 368 465 324  18 237 240 443 110 197 686 668 664  92 426 313 338\n",
      " 271 580 439  15 312 227  39 263 103 156 295 188 416 168 423 500 205  38\n",
      " 247 123 551 595 571 547 524 445 360 507  67 275  72 447 210 440 444 140\n",
      " 514 675 413 302 586 175 594 505 364 228 457  28 581 539 456 265 137 657\n",
      " 342 115  11 166 194 319 669 543 584 388  88 133 642 607 677 620 344 615\n",
      " 614 100 461 648 158 409 350 379 327 285 666 343 274 546]\n",
      "TEST: [ 60 310 124 427 630 180 549 111 483 139 542 321 346 631 106 515 347 260\n",
      " 623 250 258 587 244 624 331 105 535 172 297 159 109 257 602 557 412 198\n",
      " 415  13 503 501 130 356 326  26 634 407 459 554 609 672 219 471 684 651\n",
      " 641 451 603 254 518 414 449 600  70 279  44 526 113 441 116 129 442 585\n",
      " 479 353  51  20 184 577 428 248 208 502 395 314  47 627 104 211 386 114\n",
      "  78 292 674 497 692 272 234 359 239  85 477 533 232  27 621 568  77 564\n",
      " 665 646 504 555 608  64 288 536 691 157 495 645 216 206 566 126 493 259\n",
      " 616 469 366 348 375 408 306 399 390 687 644 283 499]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         2\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         2\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       1.00      1.00      1.00         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       0.50      1.00      0.67         1\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         2\n",
      "         41       1.00      1.00      1.00         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         2\n",
      "         50       1.00      1.00      1.00         1\n",
      "         51       1.00      0.50      0.67         2\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         2\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       0.50      1.00      0.67         1\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       0.00      0.00      0.00         1\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       1.00      1.00      1.00         1\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       0.50      1.00      0.67         1\n",
      "         75       1.00      0.50      0.67         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         2\n",
      "         80       1.00      1.00      1.00         1\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         2\n",
      "         86       1.00      1.00      1.00         2\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      0.50      0.67         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       0.67      1.00      0.80         2\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.98      0.97      0.97       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Validation #################\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         3\n",
      "          3       1.00      1.00      1.00         3\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      1.00      1.00         3\n",
      "          8       1.00      1.00      1.00         3\n",
      "          9       1.00      1.00      1.00         3\n",
      "         10       1.00      1.00      1.00         3\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         3\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       1.00      1.00      1.00         3\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         3\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         3\n",
      "         21       1.00      1.00      1.00         3\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         3\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       0.75      1.00      0.86         3\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       1.00      1.00      1.00         3\n",
      "         30       1.00      1.00      1.00         3\n",
      "         31       1.00      1.00      1.00         3\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         3\n",
      "         34       1.00      1.00      1.00         3\n",
      "         35       1.00      1.00      1.00         3\n",
      "         36       1.00      1.00      1.00         3\n",
      "         37       1.00      1.00      1.00         3\n",
      "         38       1.00      1.00      1.00         3\n",
      "         39       1.00      1.00      1.00         3\n",
      "         40       1.00      1.00      1.00         3\n",
      "         41       1.00      1.00      1.00         3\n",
      "         42       1.00      1.00      1.00         3\n",
      "         43       1.00      1.00      1.00         3\n",
      "         44       1.00      1.00      1.00         3\n",
      "         45       1.00      1.00      1.00         3\n",
      "         46       1.00      1.00      1.00         3\n",
      "         47       1.00      1.00      1.00         3\n",
      "         48       1.00      1.00      1.00         3\n",
      "         49       1.00      0.67      0.80         3\n",
      "         50       1.00      1.00      1.00         3\n",
      "         51       1.00      1.00      1.00         3\n",
      "         52       1.00      1.00      1.00         3\n",
      "         53       1.00      1.00      1.00         3\n",
      "         54       1.00      1.00      1.00         3\n",
      "         55       1.00      1.00      1.00         3\n",
      "         56       1.00      1.00      1.00         3\n",
      "         57       1.00      1.00      1.00         3\n",
      "         58       1.00      1.00      1.00         3\n",
      "         59       1.00      1.00      1.00         3\n",
      "         60       1.00      1.00      1.00         3\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         3\n",
      "         63       1.00      1.00      1.00         3\n",
      "         64       1.00      0.67      0.80         3\n",
      "         65       1.00      1.00      1.00         3\n",
      "         66       1.00      1.00      1.00         3\n",
      "         67       1.00      1.00      1.00         3\n",
      "         68       0.67      0.67      0.67         3\n",
      "         69       1.00      0.67      0.80         3\n",
      "         70       1.00      1.00      1.00         3\n",
      "         71       1.00      1.00      1.00         3\n",
      "         72       1.00      1.00      1.00         3\n",
      "         73       1.00      0.67      0.80         3\n",
      "         74       1.00      1.00      1.00         3\n",
      "         75       1.00      0.67      0.80         3\n",
      "         76       1.00      1.00      1.00         3\n",
      "         77       1.00      1.00      1.00         3\n",
      "         78       1.00      1.00      1.00         3\n",
      "         79       0.75      1.00      0.86         3\n",
      "         80       1.00      1.00      1.00         3\n",
      "         81       1.00      0.67      0.80         3\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       1.00      1.00      1.00         3\n",
      "         84       1.00      1.00      1.00         3\n",
      "         85       1.00      1.00      1.00         3\n",
      "         86       1.00      1.00      1.00         3\n",
      "         87       1.00      1.00      1.00         3\n",
      "         88       1.00      1.00      1.00         3\n",
      "         89       1.00      1.00      1.00         3\n",
      "         90       1.00      1.00      1.00         3\n",
      "         91       0.75      1.00      0.86         3\n",
      "         92       0.50      1.00      0.67         3\n",
      "         93       0.75      1.00      0.86         3\n",
      "         94       1.00      1.00      1.00         3\n",
      "         95       1.00      1.00      1.00         3\n",
      "         96       1.00      1.00      1.00         3\n",
      "         97       1.00      0.67      0.80         3\n",
      "         98       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.98      0.97      0.97       297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 294   0\n",
       "   N   0   3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.010204081632653,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.98989898989899,\n",
      "    'Rate of positive predictions': 0.98989898989899,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  1  #################\n",
      "TRAIN: [259  47  82 636  26 214 403  90 233 238 548 545 110 107 602 480 489 577\n",
      "  76 404 285 437 321  19  49 376  94 179 339 184 518 278 477 302 616 325\n",
      " 269 505 597 328 303 108 315 239 603 375  23 447 443 247 438 526 287 389\n",
      " 473 309 654  53 326 401 406 614 360 103 204 691 161 196 413   2 252 296\n",
      " 139 546 352 164 222 255 588 445 240 387  61 324 400 642 689 384 685 386\n",
      " 385 142 610 573 323 116 237 688  13 529  12 193  38  21 618 169 576 319\n",
      " 419 200   1 536 390 498 405 591 253 106 297 595 146 645 230 551 686 510\n",
      " 417 305 635 147 673 219 207 580 589 647 598 145 575 683 436 607 687 463\n",
      " 335  98 590 348 371 260 366 102 329 659 538 478  68 135 332 535 649 216\n",
      " 118 148 249 264 513 220 350 630 322  22 481 410 679 664 369  67 359 173\n",
      " 676 677 364 560 458 640 428 354 308  25  99 265 425 583 675 578 631  40\n",
      " 609 572 275  42 327 137 494 474 632 236 104 316 355  74 562 493  96 351\n",
      " 579 454 221 225 215 550 430 307 243 509 465 623  29 434 246  70 248 564\n",
      " 188  43 584 121 619 592 279 626 429 358 310 461 608  51 158 251 210 208\n",
      " 521 337  18 189   3  87 605 198  45 657 557 144 462 128 368 650 585 422\n",
      " 668 639 467 166 136 431 561 581 268 213   7  48 460 459 342 484 133 163\n",
      " 625 276 427  66 289 500 211 205  84 171 490  85 541 441 228 370 520 217\n",
      "  33 658  71 497 101 112 209 257 690 270 661 154 274 178 168  11 183 180\n",
      "  36 442  54 582 641 331 418   4 301 120 347 516 411 453 123 314 398  20\n",
      " 680 338 267 671 363 499 244 292 254 399  60 201 129 311 586 555 334 306\n",
      "  41 446 122 496 312 195 113 132 486  28  39 402  83 552 667 502 457  31\n",
      " 504 432  37 124 416 141 258 559 440 522 320 483 570 670 318 615 512  81\n",
      " 622  91 345 190  73 503  14 469 563 448 397 666 515 256 476 382 556 170\n",
      " 524 672  30 565 153 596 415 391 280 553 151 381 523 160 420 606 261 177\n",
      " 333 250  15 451 514 388  80 293 298 525 374  16 452 519 140 628 466 235\n",
      " 234 115 199 353 127 629 611 242 284 681 542 472 554  44 627 421 669  86\n",
      " 537   6  58 282 624 435 464 149 223 507  46 485 471 343 152 232 587 372\n",
      " 143 373  95 150 468 612 245 684 449 186 156 271 291 633 648 336  17 362\n",
      "  63  75 495 674  24 450 660 229 692 218 356 534  55 288 568 299 617 277\n",
      "  62 126 346 224 549  34 662 138 599 424 377 527 656 130 558 172 175 569\n",
      " 479 407 367 604 165 528 341  93 176 157 203 117 531 530]\n",
      "TEST: [621  52 349 634 286 294 600 379   9 655 185 131  69 506 281  59 492 539\n",
      " 226 361 393 159 197 273 533 456 272 517 304  10 111 601 544 182 194 383\n",
      " 665 392 357 174 511 652 547  88  78 192 105  77 653 365  27 423 433  50\n",
      "  57 426 482 340 283 414 593 439 501 409 119 181  35 643 162 444 571 290\n",
      " 644 227 637 470 395 620 206   5 594 125 167 663  92 155 114 613 241 567\n",
      " 638 263 566 678 212 330 488  89 412 109 191 396 646 540 532  64 682  72\n",
      " 491 187 380 134 408 378 317 344 394 475  65 651   0 266 574  32 313 262\n",
      " 202 300  56 100  79   8 487 455 543 508  97 295 231]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         2\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       0.50      1.00      0.67         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      0.50      0.67         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         2\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         2\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         2\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         2\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         2\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         2\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         2\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       0.67      1.00      0.80         2\n",
      "         72       1.00      1.00      1.00         2\n",
      "         73       1.00      1.00      1.00         2\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         1\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      0.50      0.67         2\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      1.00      1.00         2\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      1.00      1.00         2\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         2\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         2\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.99      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  2  #################\n",
      "TRAIN: [ 60 545 625 533  59 355 423 159 223 577 576 688  95 510 397 572  31 135\n",
      " 569 131 132 670 518  24 101 403 421 580 202 118   8 324 493 316  28 386\n",
      " 331 283 342 557 371 548 608 246  26 477 140 327 547 542 116 393 516 687\n",
      " 419 384 514 619 685 320 626 263 230 220 537 663   3 359 609  61 178 473\n",
      " 275 165 413 366 242 334 241 388 245 554 189 385 147 161 254 375 104 219\n",
      " 322 158 156 229 314 185 534 471 170 374 236 679 148 425 635 402 370 566\n",
      " 134 206 458 109 672 201  14 112   6 631 356 108 553 440 442 650 532 523\n",
      " 240  78 428  65 596  68 188 522 344 529  15 507 164 309 207 111  62  47\n",
      " 225 456 676  79 346 265 612 204 372 573 315  46 610 298 466 658 279 262\n",
      " 336 556  45 352 292 330 427  92 335  20 377 105 227 571 150  77 253 239\n",
      " 416 486 152 361  97 287 200 648 181 209 605 248  16 485  90 464 463 321\n",
      "  44 653 490 291 226 367 409 351  22 126 447 468 628  23 302 614 677  70\n",
      " 203 494 461  98 412 382 600  89 141  48 599 592 435 482 681 665 686 368\n",
      " 607 271 338 124 536 399 329 660 296 535 669 347 299 520  17 127 401 583\n",
      " 266  30 594 396 100   5 357 293 429 255 137 678 661 638 110 656 551  32\n",
      " 671 662  36 667  84 527 167 570   9  11 373 192 268 378  21 325  71 153\n",
      " 142 125 515 474 475  88 213 211 252 593 323 417 459  85 630 273  49  34\n",
      " 197 251 146 564 308  43  27 647 117 404 179 524 106 622 243 654 567 505\n",
      " 651 363 272 615 233 457 139 469 546  58 646  52  82 684 284 163 232 604\n",
      " 280 247 629 389 636 343  81  25 295 282 176 645 184 180 205 301 381 496\n",
      " 528 666 640 438 526  80 632 174 587 129 103 581 519 151 391 261 194 306\n",
      " 414 613 540 358  94 387 171 216 281 168 437 237 285 379 649  96 568 531\n",
      "  73 395 655 328 310 289 467 563  67 668 269 208 274 392 465 480 345 339\n",
      " 349 543 256 470  13 113 606 492 598  86 498 138 657 380 495 445 133 588\n",
      "  64 286  53 362 578  41 595   7 664 452 639 579 460 172 259 508 405 186\n",
      " 673 430 513 652 191 487 506 297 511 276 637 503 530 597 177 602 642 154\n",
      " 446 582 173 434 144 122 476 128 221 558 199  40 149 586 365 411 311 319\n",
      " 589 250 674   0 267 305 680 210 683 394 478 364 264  56 549 552 538 340\n",
      " 644 317 341 488 257 472  69 618 258 449 483 585 584 641 621  38 212 634\n",
      " 623 214 541 182  87 198 611 155 224 443 406  83 410 432  12 555 120  50\n",
      "  37 217 190 222 484 659 290  18  57 294 517  93 574  39]\n",
      "TEST: [560 633 196 682 499  99  63 624   4  72 383 575 145 115 479 376 193 455\n",
      " 603 157  74 422 162 565 502 119 260 509 143 195 307 183 512 400 121  29\n",
      " 408 433 692 249  66 544 561  51 114 617 444 616 441  54 107 675 431  91\n",
      " 350 420 453 500 278 643 539  33 439 559 691 244 228 489  10 407   2  35\n",
      " 450  55 231 426   1 169  19 497 313 601 166 690 360 415 348 451 521 454\n",
      " 504 187 218 123 369 525 130 160 288 332  42 175 501 238  75 354 300 326\n",
      " 448 318 215 102 390 136 562 424 418 303 333 627 337 353 462 491 689 270\n",
      " 590 620 481  76 304 398 436 312 234 550 277 235 591]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         2\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       0.50      1.00      0.67         1\n",
      "         29       1.00      0.50      0.67         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         2\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         1\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         2\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         2\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         2\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         2\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      1.00      1.00         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         2\n",
      "         84       1.00      1.00      1.00         2\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         2\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  3  #################\n",
      "TRAIN: [303 265 624 674 245 237 318  95 326 185 684 194 594 430 389 156 466 181\n",
      " 532 440 545 484 372 396 319 304 288  93 508 554 480  53 541 160 147 201\n",
      "   7 282 671 112 353 313 685 277 455 118 115 366  14 370 168 576 240 321\n",
      " 100 457 272 470 563 512 391 469 641 433 505  83 511   5 598 579 578 485\n",
      " 179 510 187 445 335 311 121 424 681 535 668  85 141 442 346 395 174 154\n",
      " 622  21 359 356 306 124 271 300 384  28 127 233  27  56 244 342 294 247\n",
      " 489 191 157 661 580 189 268 279 357 524 553 677 534 439 199 566 574 648\n",
      " 162 586  47 527 299 295  29 497  38 522 315 134 205 453   2 352 226 669\n",
      " 537 239  74  84 167 613 248 130 341   9 290 230 241 166 436 149 418  98\n",
      " 324 452 689 549 110 544 498  79 273 256 642 657 583 155 362 413 672 556\n",
      " 336 555 645 634 109 292 612 582 519  25 478 246 429 591 293 210  88 640\n",
      " 231 264 656 653 261 600 621 219 632 597  26 285 437 255 158 302  17 172\n",
      " 216 493   8 678  99 595 540 459 548 159 287 609 142 523 388 468 416 655\n",
      " 354  68 373   6  16 680 573 676 441 517 317 463 471 664 111 203 136 536\n",
      " 325 368 587 581 456  10 514  23 606 351 575 107 611 284 164 120  13 490\n",
      " 108 410  40 102 647 329 137 636 506 350 492 281 253 197  50 165 660 259\n",
      " 267 467 531 486 398 371 675 177 358 667 617  72 589 116 687 665 525  96\n",
      " 228 148 599 559 192 666 499 592 417 626 561 420  80 569 250 151 454 590\n",
      " 101 390 236 243   0 360 296  33 215 494 334 331 602 383 328 227 627  62\n",
      " 218 135 616 402 422 211 403 327 364 683 207 593  55 565 190  81 314 180\n",
      "  51  15 438 186 249  87 310 103 144 542 183   3 393 202 428 690 367 274\n",
      " 516 348 686 153  76  64 140 659 528  67 382 408  90 572 126 344 460 280\n",
      " 585  34 252 635  48 477 425 461 584 152 406 161 570 278  22 365 474 214\n",
      " 688 631  45  77 491 170 340 682 345  66 620  44 283 476 339 538  37 637\n",
      " 475 184 163 173 330 431 377 376 378 607 235 539 673 169 618 654  52  58\n",
      " 421 129 644  70  19 123 646 301 483 638 552 503 526 481  11  63 251 220\n",
      " 309 200 458  12  41 222 504 119 487 104 509 465 603 379 232 223 691 643\n",
      " 623 114 601 298 117 143 369 297 139  73 208 604 262 392 419 171 444 270\n",
      " 557 567 501 473 387 122 305 448 198  46 543 150  60 529 577 619 234 427\n",
      " 571  97 633 146 515 558 381 400 337  86 138 266 605 629 533 221  30 399\n",
      " 275  57 482 662 133 551 225 347 316 488 407 496 193 411]\n",
      "TEST: [414 242 628  94 450 630 409 355 206 521  54 363  71 394 588 224 608  32\n",
      " 105 188 464 451 568 175 332 128 333 679 596 500 426  69 320 405 213 196\n",
      "  89 229 443 257 692  42 238 401  65  92 652 530  18 289  39 125 639  49\n",
      "  82 518 415 651 380 375 472  35 349  24 670 286 397 386 106 495 307 343\n",
      "  59 513 204 610 361 625  36 260 615 308   4 479  78 131 269 195 550 502\n",
      " 145 507 462   1 212 182 276 209 449 650 432 113 178 520 217 338 560 254\n",
      " 291 258  31 423  91 434 663 446 404 176 614 132 385 412 435  61 564 322\n",
      " 312 546  20 658 649 547 562  43 447 374  75 263 323]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         2\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         2\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         2\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       1.00      1.00      1.00         2\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         1\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         2\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         2\n",
      "         54       1.00      1.00      1.00         2\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         2\n",
      "         59       1.00      1.00      1.00         1\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         1\n",
      "         64       1.00      0.50      0.67         2\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         2\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       0.67      1.00      0.80         2\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         2\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      1.00      1.00         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  4  #################\n",
      "TRAIN: [675 565 152 353 421 197 636 603  87 461  30 618   8 648 574 610 480 456\n",
      " 336  69 174 397 474 593 154  65 366  75 364 370 427 566 130 285 165 157\n",
      " 128 307 546 575 327 586 595  22   0 263 293 365 626 633 689 249  91 252\n",
      " 584 513 451 512 499   4 429 594  18 189 117 377 188 649 475  20 406 283\n",
      " 166  80 303 289 612 494 578 290 426 308  83 349 522 271  31 401 106 616\n",
      " 342 236 304 537 344 331 350 501 180  11 473 118 445 235 452 641 297  29\n",
      " 149 228 600 301  25 464 465 382 394 169 121 495 409  90  36 569 182 193\n",
      " 433 332  23  17 459 638 400 558  63 446 122 348 601  79   9 453  44 323\n",
      "  52  78  53 330 550 620 138 422 470 570  43 210 258 316 653 352 218  89\n",
      " 102 309 229 343 201 617 450 527 291 164 241 268 104  41 443 259 296 376\n",
      " 265 351 628 248 652 367  49 685 692 372 621 209 126 255 112 256 211 194\n",
      "  57 449 681 124 554 135   7 548 318 544 357 536 587 281 662  39 644 375\n",
      " 225 563 509 679 176 205 321  12 374 659 686 542  13 538 651 156  88 555\n",
      " 642  74 471 386 171 254  76  77 657 466 299 129 387  92 585  14 609 359\n",
      "  67 655 161 275 277 287 334 431 607 360 656 412  62 260 444 545  64 571\n",
      "  27 658 362  84 200 381 643 533 581  38 125 310 108  33 496 403 322 619\n",
      " 177 635 369 517  51 140 526  98 623 146 492 481 300 691  73 559 212 434\n",
      "  16 442 105 245 458 670 487 405 145 669 345 136 312  55 407 113 227 319\n",
      " 676 363 417 438 385 196 514 160 216 608  48 435 523 410 645 439 181 392\n",
      " 605  42 111 173 502 162 543 528 354 625 142 511 667 419 415 541 398 192\n",
      " 428 440 614 288 141 355 432 673 455 346 560 687 395  46 567 361 577 131\n",
      "  72  45 101 150 278 665 404 306 213 632 204 491 317 463 313 191 425 358\n",
      " 524 627 572 175 503  32 294 120 168 274  47 199 239 371 672  60 423 272\n",
      " 500 378 525 311 411 273 148 424 207 186 389 116 231 163 518 280 267 552\n",
      " 436 688 674 333 457  81  15 279 183 519 484 420 264 233 257 396  86 447\n",
      "  82   5  61 276 143  70 110 479 380 324 504 222 582 179 244 490 597 682\n",
      "  93   3 684 198 109  28 485 144 556 634 221 114   1 611 647 373 103  50\n",
      " 615 390 214 654 557 282 505 547 251 226 388 266 598  35 270 671 413 408\n",
      " 529 123 224 553 178  95 339  94 230 347 478 379 588 337 220 340 437 483\n",
      " 416 247  10 243 246 187  37 391 540 185 100 320 535 329 506 119 132 184\n",
      " 590 521 631 680 315 356 606 383 202 325 139 305 206 127]\n",
      "TEST: [242 153 579 147 482 666 460 510 531 115 215  56 219 468 441 137 190 208\n",
      " 167  54 134 568 107 629  66 462 250 472 646 664 589 151 170 591 592 489\n",
      " 668 530 497 234 596 551 195 295 302 640 488 549 561 580 269 630 520 172\n",
      " 562   2  19 286 253  71 298 158 583 573 507 326 328  34 599 467  26 539\n",
      " 203 238  24 622 284 576 661   6 262 399 338 418 414  21 639 602 476 660\n",
      "  85 477 486 690 663 613 604 448 232 532  99 564 677 384 240 469 292 534\n",
      " 678 314 368 650 516 683 341 637 454 237 223 430  96 159 508 335 261 217\n",
      "  97  58 155  40 133  59 624 498 493 393 515 402  68]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       0.50      1.00      0.67         1\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         2\n",
      "         14       1.00      1.00      1.00         2\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       1.00      1.00      1.00         2\n",
      "         29       1.00      1.00      1.00         2\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       0.50      1.00      0.67         1\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "         37       0.50      1.00      0.67         1\n",
      "         38       1.00      0.50      0.67         2\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       1.00      1.00      1.00         1\n",
      "         42       1.00      1.00      1.00         1\n",
      "         43       1.00      1.00      1.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         2\n",
      "         51       1.00      1.00      1.00         1\n",
      "         52       1.00      1.00      1.00         1\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         2\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         2\n",
      "         66       1.00      1.00      1.00         1\n",
      "         67       1.00      1.00      1.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         2\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         2\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         2\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       1.00      1.00      1.00         2\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      0.50      0.67         2\n",
      "         85       1.00      1.00      1.00         2\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         2\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       1.00      0.50      0.67         2\n",
      "         93       1.00      1.00      1.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.99      0.98      0.98       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 137   0\n",
       "   N   0   2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0145985401459854,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9856115107913669,\n",
      "    'Rate of positive predictions': 0.9856115107913669,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  5  #################\n",
      "TRAIN: [556 165  54 370 309 193 269 229 491  59 492 565 362 418 612 128 606 149\n",
      " 422  98 241 381 304 635 604 336 654 261 355 231 187 200 475 199 463 522\n",
      "  49 639 472 649 120 508 480 420 670 296  73  94 108 212 435 392 317  63\n",
      " 308 663  83 145 218 223 593 653  62 268 678 243 146 470   2 102 173 235\n",
      " 679 281 582   7   5 575 270 148 385 485 659  65  95 421 150 303 484 330\n",
      "  96 374 397  22 517 578 618 251 534 464 162  80  21   6 380 400 561  52\n",
      " 544 538  61 401 278 550 154 334   0 673 191 127 572 230 256 142 629 121\n",
      " 430 252 341 225   9 131 531 425  48 141 207 176 255  41 410 373 454 215\n",
      " 633 224 617 376 195 101 242  10 417 349  75 153 332 540 358 494 286 487\n",
      " 601  33 610 329 394 169  32  53  97 597 434 583  35 357 289 112 322 406\n",
      " 548 436 448   3 151  68 579 626 284 384 688 213 509 369  86 478  84 490\n",
      " 361 545 320 371  24 574 432  71 685 192 458 613 294 553 117 249  42 446\n",
      " 404 290  55 433 291 305 277 378 280 262 640  56 253  79 363 462 178 163\n",
      " 377 523 431 236  82 690 468  99 558 315 155 573 596 311 569 398 393 202\n",
      " 266   8 209 520 450 622 403 474 476 135 681 125 528 619 563 570 605 647\n",
      " 632 671 429 246   1 160 143 318  45 396  19 204 107 293 354 222  40  87\n",
      " 300 598  34   4 510 372 625 189 588 552  93  69  50 683 161  31  91 519\n",
      " 658 323 196 333 411 516 201 650  57 496 486 527 460 167 656  66 682 170\n",
      " 382 287 525 264 226 676 174 655 636 592 567 316 680 405 171 689 182 466\n",
      " 437 118 481 345 144 389 489 521 352 473 488 221 383 185 591 438 628 183\n",
      " 402  58 513 652 214 325 576 177 340 506 335 667 147 298 134 511 452  76\n",
      " 122 589 638 217 611  43 560 267 307 138 512  25  74 453 301 203  37 186\n",
      " 282  16  36 530 238  29 337 559  90 424  17 328 367 661 660 164 119 419\n",
      " 599 637 132 387 562 498 467 455 537 136 220  46 351  12 643 529 541  14\n",
      " 482 532 179 152 276 365 590 339 391  30 245 273  81  23  89 181 233 662\n",
      " 190 299 368 465 324  18 237 240 443 110 197 686 668 664  92 426 313 338\n",
      " 271 580 439  15 312 227  39 263 103 156 295 188 416 168 423 500 205  38\n",
      " 247 123 551 595 571 547 524 445 360 507  67 275  72 447 210 440 444 140\n",
      " 514 675 413 302 586 175 594 505 364 228 457  28 581 539 456 265 137 657\n",
      " 342 115  11 166 194 319 669 543 584 388  88 133 642 607 677 620 344 615\n",
      " 614 100 461 648 158 409 350 379 327 285 666 343 274 546]\n",
      "TEST: [ 60 310 124 427 630 180 549 111 483 139 542 321 346 631 106 515 347 260\n",
      " 623 250 258 587 244 624 331 105 535 172 297 159 109 257 602 557 412 198\n",
      " 415  13 503 501 130 356 326  26 634 407 459 554 609 672 219 471 684 651\n",
      " 641 451 603 254 518 414 449 600  70 279  44 526 113 441 116 129 442 585\n",
      " 479 353  51  20 184 577 428 248 208 502 395 314  47 627 104 211 386 114\n",
      "  78 292 674 497 692 272 234 359 239  85 477 533 232  27 621 568  77 564\n",
      " 665 646 504 555 608  64 288 536 691 157 495 645 216 206 566 126 493 259\n",
      " 616 469 366 348 375 408 306 399 390 687 644 283 499]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      1.00      1.00         2\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         2\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         2\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       0.50      1.00      0.67         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       1.00      1.00      1.00         2\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       1.00      1.00      1.00         2\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         2\n",
      "         41       1.00      1.00      1.00         2\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         2\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       1.00      1.00      1.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       1.00      1.00      1.00         1\n",
      "         49       1.00      1.00      1.00         2\n",
      "         50       1.00      1.00      1.00         1\n",
      "         51       1.00      0.50      0.67         2\n",
      "         52       1.00      1.00      1.00         2\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       1.00      1.00      1.00         1\n",
      "         56       1.00      1.00      1.00         1\n",
      "         57       1.00      1.00      1.00         1\n",
      "         58       1.00      1.00      1.00         2\n",
      "         59       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       1.00      1.00      1.00         1\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       1.00      1.00      1.00         1\n",
      "         71       1.00      1.00      1.00         1\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       0.50      1.00      0.67         1\n",
      "         75       1.00      1.00      1.00         2\n",
      "         76       1.00      1.00      1.00         2\n",
      "         77       1.00      1.00      1.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         2\n",
      "         80       1.00      1.00      1.00         1\n",
      "         81       1.00      1.00      1.00         1\n",
      "         82       1.00      1.00      1.00         2\n",
      "         83       1.00      1.00      1.00         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         2\n",
      "         86       1.00      1.00      1.00         2\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       1.00      1.00      1.00         2\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       1.00      0.50      0.67         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         2\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         1\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.99      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Validation #################\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         3\n",
      "          3       1.00      1.00      1.00         3\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      1.00      1.00         3\n",
      "          8       1.00      1.00      1.00         3\n",
      "          9       1.00      1.00      1.00         3\n",
      "         10       0.75      1.00      0.86         3\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         3\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       1.00      1.00      1.00         3\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         3\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         3\n",
      "         21       1.00      1.00      1.00         3\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         3\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       0.75      1.00      0.86         3\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       1.00      1.00      1.00         3\n",
      "         30       1.00      1.00      1.00         3\n",
      "         31       1.00      1.00      1.00         3\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         3\n",
      "         34       1.00      1.00      1.00         3\n",
      "         35       1.00      1.00      1.00         3\n",
      "         36       1.00      0.67      0.80         3\n",
      "         37       1.00      1.00      1.00         3\n",
      "         38       1.00      1.00      1.00         3\n",
      "         39       0.75      1.00      0.86         3\n",
      "         40       1.00      1.00      1.00         3\n",
      "         41       1.00      1.00      1.00         3\n",
      "         42       1.00      1.00      1.00         3\n",
      "         43       1.00      1.00      1.00         3\n",
      "         44       1.00      1.00      1.00         3\n",
      "         45       1.00      1.00      1.00         3\n",
      "         46       1.00      1.00      1.00         3\n",
      "         47       1.00      1.00      1.00         3\n",
      "         48       1.00      1.00      1.00         3\n",
      "         49       1.00      0.67      0.80         3\n",
      "         50       1.00      1.00      1.00         3\n",
      "         51       1.00      1.00      1.00         3\n",
      "         52       1.00      1.00      1.00         3\n",
      "         53       1.00      1.00      1.00         3\n",
      "         54       1.00      1.00      1.00         3\n",
      "         55       1.00      1.00      1.00         3\n",
      "         56       1.00      1.00      1.00         3\n",
      "         57       1.00      1.00      1.00         3\n",
      "         58       1.00      1.00      1.00         3\n",
      "         59       1.00      1.00      1.00         3\n",
      "         60       1.00      1.00      1.00         3\n",
      "         61       1.00      1.00      1.00         3\n",
      "         62       1.00      1.00      1.00         3\n",
      "         63       1.00      1.00      1.00         3\n",
      "         64       1.00      0.67      0.80         3\n",
      "         65       1.00      1.00      1.00         3\n",
      "         66       1.00      1.00      1.00         3\n",
      "         67       1.00      1.00      1.00         3\n",
      "         68       1.00      0.67      0.80         3\n",
      "         69       1.00      1.00      1.00         3\n",
      "         70       1.00      1.00      1.00         3\n",
      "         71       1.00      1.00      1.00         3\n",
      "         72       1.00      1.00      1.00         3\n",
      "         73       1.00      0.67      0.80         3\n",
      "         74       1.00      1.00      1.00         3\n",
      "         75       1.00      0.67      0.80         3\n",
      "         76       0.75      1.00      0.86         3\n",
      "         77       1.00      1.00      1.00         3\n",
      "         78       1.00      1.00      1.00         3\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       1.00      1.00      1.00         3\n",
      "         81       1.00      1.00      1.00         3\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       1.00      1.00      1.00         3\n",
      "         84       1.00      1.00      1.00         3\n",
      "         85       1.00      0.67      0.80         3\n",
      "         86       1.00      1.00      1.00         3\n",
      "         87       1.00      1.00      1.00         3\n",
      "         88       1.00      1.00      1.00         3\n",
      "         89       1.00      1.00      1.00         3\n",
      "         90       1.00      1.00      1.00         3\n",
      "         91       1.00      1.00      1.00         3\n",
      "         92       0.50      1.00      0.67         3\n",
      "         93       0.75      1.00      0.86         3\n",
      "         94       1.00      1.00      1.00         3\n",
      "         95       1.00      1.00      1.00         3\n",
      "         96       1.00      1.00      1.00         3\n",
      "         97       1.00      0.67      0.80         3\n",
      "         98       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.98      0.97      0.97       297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 294   0\n",
       "   N   0   3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.010204081632653,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.98989898989899,\n",
      "    'Rate of positive predictions': 0.98989898989899,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Training Fold:  1  #################\n",
      "TRAIN: [259  47  82 636  26 214 403  90 233 238 548 545 110 107 602 480 489 577\n",
      "  76 404 285 437 321  19  49 376  94 179 339 184 518 278 477 302 616 325\n",
      " 269 505 597 328 303 108 315 239 603 375  23 447 443 247 438 526 287 389\n",
      " 473 309 654  53 326 401 406 614 360 103 204 691 161 196 413   2 252 296\n",
      " 139 546 352 164 222 255 588 445 240 387  61 324 400 642 689 384 685 386\n",
      " 385 142 610 573 323 116 237 688  13 529  12 193  38  21 618 169 576 319\n",
      " 419 200   1 536 390 498 405 591 253 106 297 595 146 645 230 551 686 510\n",
      " 417 305 635 147 673 219 207 580 589 647 598 145 575 683 436 607 687 463\n",
      " 335  98 590 348 371 260 366 102 329 659 538 478  68 135 332 535 649 216\n",
      " 118 148 249 264 513 220 350 630 322  22 481 410 679 664 369  67 359 173\n",
      " 676 677 364 560 458 640 428 354 308  25  99 265 425 583 675 578 631  40\n",
      " 609 572 275  42 327 137 494 474 632 236 104 316 355  74 562 493  96 351\n",
      " 579 454 221 225 215 550 430 307 243 509 465 623  29 434 246  70 248 564\n",
      " 188  43 584 121 619 592 279 626 429 358 310 461 608  51 158 251 210 208\n",
      " 521 337  18 189   3  87 605 198  45 657 557 144 462 128 368 650 585 422\n",
      " 668 639 467 166 136 431 561 581 268 213   7  48 460 459 342 484 133 163\n",
      " 625 276 427  66 289 500 211 205  84 171 490  85 541 441 228 370 520 217\n",
      "  33 658  71 497 101 112 209 257 690 270 661 154 274 178 168  11 183 180\n",
      "  36 442  54 582 641 331 418   4 301 120 347 516 411 453 123 314 398  20\n",
      " 680 338 267 671 363 499 244 292 254 399  60 201 129 311 586 555 334 306\n",
      "  41 446 122 496 312 195 113 132 486  28  39 402  83 552 667 502 457  31\n",
      " 504 432  37 124 416 141 258 559 440 522 320 483 570 670 318 615 512  81\n",
      " 622  91 345 190  73 503  14 469 563 448 397 666 515 256 476 382 556 170\n",
      " 524 672  30 565 153 596 415 391 280 553 151 381 523 160 420 606 261 177\n",
      " 333 250  15 451 514 388  80 293 298 525 374  16 452 519 140 628 466 235\n",
      " 234 115 199 353 127 629 611 242 284 681 542 472 554  44 627 421 669  86\n",
      " 537   6  58 282 624 435 464 149 223 507  46 485 471 343 152 232 587 372\n",
      " 143 373  95 150 468 612 245 684 449 186 156 271 291 633 648 336  17 362\n",
      "  63  75 495 674  24 450 660 229 692 218 356 534  55 288 568 299 617 277\n",
      "  62 126 346 224 549  34 662 138 599 424 377 527 656 130 558 172 175 569\n",
      " 479 407 367 604 165 528 341  93 176 157 203 117 531 530]\n",
      "TEST: [621  52 349 634 286 294 600 379   9 655 185 131  69 506 281  59 492 539\n",
      " 226 361 393 159 197 273 533 456 272 517 304  10 111 601 544 182 194 383\n",
      " 665 392 357 174 511 652 547  88  78 192 105  77 653 365  27 423 433  50\n",
      "  57 426 482 340 283 414 593 439 501 409 119 181  35 643 162 444 571 290\n",
      " 644 227 637 470 395 620 206   5 594 125 167 663  92 155 114 613 241 567\n",
      " 638 263 566 678 212 330 488  89 412 109 191 396 646 540 532  64 682  72\n",
      " 491 187 380 134 408 378 317 344 394 475  65 651   0 266 574  32 313 262\n",
      " 202 300  56 100  79   8 487 455 543 508  97 295 231]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.50         1\n",
      "          1       0.33      1.00      0.50         1\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       0.33      1.00      0.50         1\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.33      1.00      0.50         1\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.00         2\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.00         2\n",
      "         11       0.50      1.00      0.67         1\n",
      "         12       0.14      1.00      0.25         1\n",
      "         13       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       0.33      1.00      0.50         1\n",
      "         17       0.50      1.00      0.67         1\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       0.00      0.00      0.00         2\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       0.00      0.00      0.00         2\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       0.50      1.00      0.67         1\n",
      "         25       0.50      1.00      0.67         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.50      1.00      0.67         1\n",
      "         29       0.00      0.00      0.00         1\n",
      "         30       0.50      1.00      0.67         1\n",
      "         31       0.00      0.00      0.00         1\n",
      "         32       0.33      1.00      0.50         1\n",
      "         33       0.00      0.00      0.00         2\n",
      "         34       0.00      0.00      0.00         2\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.33      1.00      0.50         1\n",
      "         37       0.20      1.00      0.33         1\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.33      1.00      0.50         1\n",
      "         40       0.25      1.00      0.40         1\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00         2\n",
      "         43       0.00      0.00      0.00         2\n",
      "         44       0.50      1.00      0.67         1\n",
      "         45       0.00      0.00      0.00         2\n",
      "         46       0.12      1.00      0.22         1\n",
      "         47       0.50      1.00      0.67         1\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.50      1.00      0.67         1\n",
      "         50       0.00      0.00      0.00         2\n",
      "         51       0.00      0.00      0.00         2\n",
      "         52       0.00      0.00      0.00         2\n",
      "         53       0.00      0.00      0.00         2\n",
      "         54       0.33      1.00      0.50         1\n",
      "         55       0.00      0.00      0.00         2\n",
      "         56       0.17      1.00      0.29         1\n",
      "         57       0.00      0.00      0.00         2\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       0.25      1.00      0.40         1\n",
      "         64       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         2\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       1.00      1.00      1.00         1\n",
      "         68       0.00      0.00      0.00         2\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       0.50      1.00      0.67         1\n",
      "         71       0.00      0.00      0.00         2\n",
      "         72       0.00      0.00      0.00         2\n",
      "         73       0.00      0.00      0.00         2\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       1.00      1.00      1.00         1\n",
      "         76       1.00      1.00      1.00         1\n",
      "         77       0.50      1.00      0.67         1\n",
      "         78       0.14      1.00      0.25         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.12      1.00      0.22         1\n",
      "         82       0.00      0.00      0.00         2\n",
      "         83       0.00      0.00      0.00         2\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       0.50      1.00      0.67         1\n",
      "         86       0.20      1.00      0.33         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       0.25      1.00      0.40         1\n",
      "         89       0.50      1.00      0.67         1\n",
      "         90       0.33      1.00      0.50         1\n",
      "         91       1.00      1.00      1.00         1\n",
      "         92       0.00      0.00      0.00         2\n",
      "         93       1.00      1.00      1.00         1\n",
      "         94       0.00      0.00      0.00         2\n",
      "         95       1.00      1.00      1.00         1\n",
      "         96       0.00      0.00      0.00         2\n",
      "         97       0.25      1.00      0.40         1\n",
      "         98       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.22      0.37      0.25       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 136   2\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 4.0,\n",
      "    'Accuracy': 0.9856115107913669,\n",
      "    'Error rate': 0.014388489208633094,\n",
      "    'False negative rate': 0.014492753623188406,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.3333333333333333,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9784172661870504,\n",
      "    'Sensitivity (true positives rate)': 0.9855072463768116,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.5,\n",
      "    'kappa': 0.4945454545454513}\n",
      "###################### Training Fold:  2  #################\n",
      "TRAIN: [ 60 545 625 533  59 355 423 159 223 577 576 688  95 510 397 572  31 135\n",
      " 569 131 132 670 518  24 101 403 421 580 202 118   8 324 493 316  28 386\n",
      " 331 283 342 557 371 548 608 246  26 477 140 327 547 542 116 393 516 687\n",
      " 419 384 514 619 685 320 626 263 230 220 537 663   3 359 609  61 178 473\n",
      " 275 165 413 366 242 334 241 388 245 554 189 385 147 161 254 375 104 219\n",
      " 322 158 156 229 314 185 534 471 170 374 236 679 148 425 635 402 370 566\n",
      " 134 206 458 109 672 201  14 112   6 631 356 108 553 440 442 650 532 523\n",
      " 240  78 428  65 596  68 188 522 344 529  15 507 164 309 207 111  62  47\n",
      " 225 456 676  79 346 265 612 204 372 573 315  46 610 298 466 658 279 262\n",
      " 336 556  45 352 292 330 427  92 335  20 377 105 227 571 150  77 253 239\n",
      " 416 486 152 361  97 287 200 648 181 209 605 248  16 485  90 464 463 321\n",
      "  44 653 490 291 226 367 409 351  22 126 447 468 628  23 302 614 677  70\n",
      " 203 494 461  98 412 382 600  89 141  48 599 592 435 482 681 665 686 368\n",
      " 607 271 338 124 536 399 329 660 296 535 669 347 299 520  17 127 401 583\n",
      " 266  30 594 396 100   5 357 293 429 255 137 678 661 638 110 656 551  32\n",
      " 671 662  36 667  84 527 167 570   9  11 373 192 268 378  21 325  71 153\n",
      " 142 125 515 474 475  88 213 211 252 593 323 417 459  85 630 273  49  34\n",
      " 197 251 146 564 308  43  27 647 117 404 179 524 106 622 243 654 567 505\n",
      " 651 363 272 615 233 457 139 469 546  58 646  52  82 684 284 163 232 604\n",
      " 280 247 629 389 636 343  81  25 295 282 176 645 184 180 205 301 381 496\n",
      " 528 666 640 438 526  80 632 174 587 129 103 581 519 151 391 261 194 306\n",
      " 414 613 540 358  94 387 171 216 281 168 437 237 285 379 649  96 568 531\n",
      "  73 395 655 328 310 289 467 563  67 668 269 208 274 392 465 480 345 339\n",
      " 349 543 256 470  13 113 606 492 598  86 498 138 657 380 495 445 133 588\n",
      "  64 286  53 362 578  41 595   7 664 452 639 579 460 172 259 508 405 186\n",
      " 673 430 513 652 191 487 506 297 511 276 637 503 530 597 177 602 642 154\n",
      " 446 582 173 434 144 122 476 128 221 558 199  40 149 586 365 411 311 319\n",
      " 589 250 674   0 267 305 680 210 683 394 478 364 264  56 549 552 538 340\n",
      " 644 317 341 488 257 472  69 618 258 449 483 585 584 641 621  38 212 634\n",
      " 623 214 541 182  87 198 611 155 224 443 406  83 410 432  12 555 120  50\n",
      "  37 217 190 222 484 659 290  18  57 294 517  93 574  39]\n",
      "TEST: [560 633 196 682 499  99  63 624   4  72 383 575 145 115 479 376 193 455\n",
      " 603 157  74 422 162 565 502 119 260 509 143 195 307 183 512 400 121  29\n",
      " 408 433 692 249  66 544 561  51 114 617 444 616 441  54 107 675 431  91\n",
      " 350 420 453 500 278 643 539  33 439 559 691 244 228 489  10 407   2  35\n",
      " 450  55 231 426   1 169  19 497 313 601 166 690 360 415 348 451 521 454\n",
      " 504 187 218 123 369 525 130 160 288 332  42 175 501 238  75 354 300 326\n",
      " 448 318 215 102 390 136 562 424 418 303 333 627 337 353 462 491 689 270\n",
      " 590 620 481  76 304 398 436 312 234 550 277 235 591]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.50         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       0.25      1.00      0.40         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.50      1.00      0.67         1\n",
      "          7       0.50      1.00      0.67         1\n",
      "          8       0.00      0.00      0.00         2\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.00         2\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       0.25      1.00      0.40         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       0.00      0.00      0.00         2\n",
      "         20       0.25      1.00      0.40         1\n",
      "         21       0.00      0.00      0.00         2\n",
      "         22       0.33      1.00      0.50         1\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       0.00      0.00      0.00         2\n",
      "         25       0.50      1.00      0.67         1\n",
      "         26       0.00      0.00      0.00         2\n",
      "         27       0.11      1.00      0.20         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.00      0.00      0.00         2\n",
      "         30       0.00      0.00      0.00         2\n",
      "         31       0.00      0.00      0.00         2\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      1.00      1.00         1\n",
      "         34       0.00      0.00      0.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       0.00      0.00      0.00         2\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.17      1.00      0.29         1\n",
      "         40       0.33      1.00      0.50         1\n",
      "         41       0.50      1.00      0.67         1\n",
      "         42       0.00      0.00      0.00         2\n",
      "         43       0.00      0.00      0.00         2\n",
      "         44       1.00      1.00      1.00         1\n",
      "         45       0.50      1.00      0.67         1\n",
      "         46       0.00      0.00      0.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       0.50      1.00      0.67         1\n",
      "         49       0.00      0.00      0.00         1\n",
      "         50       0.33      1.00      0.50         1\n",
      "         51       0.33      1.00      0.50         1\n",
      "         52       0.20      1.00      0.33         1\n",
      "         53       0.50      1.00      0.67         1\n",
      "         54       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       0.00      0.00      0.00         2\n",
      "         57       0.50      1.00      0.67         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00         2\n",
      "         63       0.33      1.00      0.50         1\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       0.50      1.00      0.67         1\n",
      "         66       0.00      0.00      0.00         1\n",
      "         67       0.00      0.00      0.00         2\n",
      "         68       0.50      1.00      0.67         1\n",
      "         69       1.00      1.00      1.00         1\n",
      "         70       0.00      0.00      0.00         2\n",
      "         71       0.00      0.00      0.00         2\n",
      "         72       0.50      1.00      0.67         1\n",
      "         73       0.00      0.00      0.00         2\n",
      "         74       0.00      0.00      0.00         2\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.33      1.00      0.50         1\n",
      "         77       0.00      0.00      0.00         2\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.00      0.00      0.00         2\n",
      "         82       0.20      1.00      0.33         1\n",
      "         83       0.00      0.00      0.00         2\n",
      "         84       0.00      0.00      0.00         2\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       0.50      1.00      0.67         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       0.00      0.00      0.00         1\n",
      "         89       0.00      0.00      0.00         2\n",
      "         90       0.25      1.00      0.40         1\n",
      "         91       0.33      1.00      0.50         1\n",
      "         92       0.25      1.00      0.40         1\n",
      "         93       0.00      0.00      0.00         2\n",
      "         94       0.17      1.00      0.29         1\n",
      "         95       0.50      1.00      0.67         1\n",
      "         96       0.33      1.00      0.50         1\n",
      "         97       0.00      0.00      0.00         2\n",
      "         98       0.50      1.00      0.67         1\n",
      "\n",
      "avg / total       0.22      0.37      0.25       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 136   2\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 6.0,\n",
      "    'Accuracy': 0.9856115107913669,\n",
      "    'Error rate': 0.014388489208633094,\n",
      "    'False negative rate': 0.014492753623188406,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.3333333333333333,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9784172661870504,\n",
      "    'Sensitivity (true positives rate)': 0.9855072463768116,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.5,\n",
      "    'kappa': 0.4945454545454513}\n",
      "###################### Training Fold:  3  #################\n",
      "TRAIN: [303 265 624 674 245 237 318  95 326 185 684 194 594 430 389 156 466 181\n",
      " 532 440 545 484 372 396 319 304 288  93 508 554 480  53 541 160 147 201\n",
      "   7 282 671 112 353 313 685 277 455 118 115 366  14 370 168 576 240 321\n",
      " 100 457 272 470 563 512 391 469 641 433 505  83 511   5 598 579 578 485\n",
      " 179 510 187 445 335 311 121 424 681 535 668  85 141 442 346 395 174 154\n",
      " 622  21 359 356 306 124 271 300 384  28 127 233  27  56 244 342 294 247\n",
      " 489 191 157 661 580 189 268 279 357 524 553 677 534 439 199 566 574 648\n",
      " 162 586  47 527 299 295  29 497  38 522 315 134 205 453   2 352 226 669\n",
      " 537 239  74  84 167 613 248 130 341   9 290 230 241 166 436 149 418  98\n",
      " 324 452 689 549 110 544 498  79 273 256 642 657 583 155 362 413 672 556\n",
      " 336 555 645 634 109 292 612 582 519  25 478 246 429 591 293 210  88 640\n",
      " 231 264 656 653 261 600 621 219 632 597  26 285 437 255 158 302  17 172\n",
      " 216 493   8 678  99 595 540 459 548 159 287 609 142 523 388 468 416 655\n",
      " 354  68 373   6  16 680 573 676 441 517 317 463 471 664 111 203 136 536\n",
      " 325 368 587 581 456  10 514  23 606 351 575 107 611 284 164 120  13 490\n",
      " 108 410  40 102 647 329 137 636 506 350 492 281 253 197  50 165 660 259\n",
      " 267 467 531 486 398 371 675 177 358 667 617  72 589 116 687 665 525  96\n",
      " 228 148 599 559 192 666 499 592 417 626 561 420  80 569 250 151 454 590\n",
      " 101 390 236 243   0 360 296  33 215 494 334 331 602 383 328 227 627  62\n",
      " 218 135 616 402 422 211 403 327 364 683 207 593  55 565 190  81 314 180\n",
      "  51  15 438 186 249  87 310 103 144 542 183   3 393 202 428 690 367 274\n",
      " 516 348 686 153  76  64 140 659 528  67 382 408  90 572 126 344 460 280\n",
      " 585  34 252 635  48 477 425 461 584 152 406 161 570 278  22 365 474 214\n",
      " 688 631  45  77 491 170 340 682 345  66 620  44 283 476 339 538  37 637\n",
      " 475 184 163 173 330 431 377 376 378 607 235 539 673 169 618 654  52  58\n",
      " 421 129 644  70  19 123 646 301 483 638 552 503 526 481  11  63 251 220\n",
      " 309 200 458  12  41 222 504 119 487 104 509 465 603 379 232 223 691 643\n",
      " 623 114 601 298 117 143 369 297 139  73 208 604 262 392 419 171 444 270\n",
      " 557 567 501 473 387 122 305 448 198  46 543 150  60 529 577 619 234 427\n",
      " 571  97 633 146 515 558 381 400 337  86 138 266 605 629 533 221  30 399\n",
      " 275  57 482 662 133 551 225 347 316 488 407 496 193 411]\n",
      "TEST: [414 242 628  94 450 630 409 355 206 521  54 363  71 394 588 224 608  32\n",
      " 105 188 464 451 568 175 332 128 333 679 596 500 426  69 320 405 213 196\n",
      "  89 229 443 257 692  42 238 401  65  92 652 530  18 289  39 125 639  49\n",
      "  82 518 415 651 380 375 472  35 349  24 670 286 397 386 106 495 307 343\n",
      "  59 513 204 610 361 625  36 260 615 308   4 479  78 131 269 195 550 502\n",
      " 145 507 462   1 212 182 276 209 449 650 432 113 178 520 217 338 560 254\n",
      " 291 258  31 423  91 434 663 446 404 176 614 132 385 412 435  61 564 322\n",
      " 312 546  20 658 649 547 562  43 447 374  75 263 323]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      1.00      0.40         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       0.00      0.00      0.00         2\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.25      1.00      0.40         1\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.33      1.00      0.50         1\n",
      "          8       0.20      1.00      0.33         1\n",
      "          9       0.20      1.00      0.33         1\n",
      "         10       0.50      1.00      0.67         1\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         2\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       0.33      1.00      0.50         1\n",
      "         15       1.00      1.00      1.00         1\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.50      1.00      0.67         1\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       1.00      1.00      1.00         1\n",
      "         25       0.50      1.00      0.67         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.00      0.00      0.00         2\n",
      "         29       0.33      1.00      0.50         1\n",
      "         30       0.00      0.00      0.00         2\n",
      "         31       0.33      1.00      0.50         1\n",
      "         32       0.50      1.00      0.67         1\n",
      "         33       0.00      0.00      0.00         2\n",
      "         34       0.50      1.00      0.67         1\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.50      1.00      0.67         1\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.25      1.00      0.40         1\n",
      "         40       1.00      1.00      1.00         1\n",
      "         41       0.17      1.00      0.29         1\n",
      "         42       0.33      1.00      0.50         1\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       0.00      0.00      0.00         2\n",
      "         45       0.50      1.00      0.67         1\n",
      "         46       0.00      0.00      0.00         2\n",
      "         47       0.00      0.00      0.00         2\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.50      1.00      0.67         1\n",
      "         50       0.00      0.00      0.00         2\n",
      "         51       0.00      0.00      0.00         1\n",
      "         52       0.00      0.00      0.00         2\n",
      "         53       0.00      0.00      0.00         2\n",
      "         54       0.00      0.00      0.00         2\n",
      "         55       0.50      1.00      0.67         1\n",
      "         56       0.33      1.00      0.50         1\n",
      "         57       0.33      1.00      0.50         1\n",
      "         58       0.00      0.00      0.00         2\n",
      "         59       0.25      1.00      0.40         1\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       0.33      1.00      0.50         1\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       0.50      1.00      0.67         1\n",
      "         64       0.00      0.00      0.00         2\n",
      "         65       0.25      1.00      0.40         1\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       0.50      1.00      0.67         1\n",
      "         68       0.00      0.00      0.00         2\n",
      "         69       0.50      1.00      0.67         1\n",
      "         70       0.00      0.00      0.00         2\n",
      "         71       0.00      0.00      0.00         2\n",
      "         72       0.50      1.00      0.67         1\n",
      "         73       1.00      1.00      1.00         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.50      1.00      0.67         1\n",
      "         77       0.50      1.00      0.67         1\n",
      "         78       0.50      1.00      0.67         1\n",
      "         79       0.00      0.00      0.00         2\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.00      0.00      0.00         2\n",
      "         82       1.00      1.00      1.00         1\n",
      "         83       0.17      1.00      0.29         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       1.00      1.00      1.00         1\n",
      "         86       0.20      1.00      0.33         1\n",
      "         87       1.00      1.00      1.00         1\n",
      "         88       1.00      1.00      1.00         1\n",
      "         89       1.00      1.00      1.00         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       0.00      0.00      0.00         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       0.00      0.00      0.00         2\n",
      "         94       0.50      1.00      0.67         1\n",
      "         95       0.20      1.00      0.33         1\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       0.25      1.00      0.40         1\n",
      "         98       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.24      0.41      0.29       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 135   3\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 16.0,\n",
      "    'Accuracy': 0.9784172661870504,\n",
      "    'Error rate': 0.02158273381294964,\n",
      "    'False negative rate': 0.021739130434782608,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.25,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9712230215827338,\n",
      "    'Sensitivity (true positives rate)': 0.9782608695652174,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.4,\n",
      "    'kappa': 0.3930131004366815}\n",
      "###################### Training Fold:  4  #################\n",
      "TRAIN: [675 565 152 353 421 197 636 603  87 461  30 618   8 648 574 610 480 456\n",
      " 336  69 174 397 474 593 154  65 366  75 364 370 427 566 130 285 165 157\n",
      " 128 307 546 575 327 586 595  22   0 263 293 365 626 633 689 249  91 252\n",
      " 584 513 451 512 499   4 429 594  18 189 117 377 188 649 475  20 406 283\n",
      " 166  80 303 289 612 494 578 290 426 308  83 349 522 271  31 401 106 616\n",
      " 342 236 304 537 344 331 350 501 180  11 473 118 445 235 452 641 297  29\n",
      " 149 228 600 301  25 464 465 382 394 169 121 495 409  90  36 569 182 193\n",
      " 433 332  23  17 459 638 400 558  63 446 122 348 601  79   9 453  44 323\n",
      "  52  78  53 330 550 620 138 422 470 570  43 210 258 316 653 352 218  89\n",
      " 102 309 229 343 201 617 450 527 291 164 241 268 104  41 443 259 296 376\n",
      " 265 351 628 248 652 367  49 685 692 372 621 209 126 255 112 256 211 194\n",
      "  57 449 681 124 554 135   7 548 318 544 357 536 587 281 662  39 644 375\n",
      " 225 563 509 679 176 205 321  12 374 659 686 542  13 538 651 156  88 555\n",
      " 642  74 471 386 171 254  76  77 657 466 299 129 387  92 585  14 609 359\n",
      "  67 655 161 275 277 287 334 431 607 360 656 412  62 260 444 545  64 571\n",
      "  27 658 362  84 200 381 643 533 581  38 125 310 108  33 496 403 322 619\n",
      " 177 635 369 517  51 140 526  98 623 146 492 481 300 691  73 559 212 434\n",
      "  16 442 105 245 458 670 487 405 145 669 345 136 312  55 407 113 227 319\n",
      " 676 363 417 438 385 196 514 160 216 608  48 435 523 410 645 439 181 392\n",
      " 605  42 111 173 502 162 543 528 354 625 142 511 667 419 415 541 398 192\n",
      " 428 440 614 288 141 355 432 673 455 346 560 687 395  46 567 361 577 131\n",
      "  72  45 101 150 278 665 404 306 213 632 204 491 317 463 313 191 425 358\n",
      " 524 627 572 175 503  32 294 120 168 274  47 199 239 371 672  60 423 272\n",
      " 500 378 525 311 411 273 148 424 207 186 389 116 231 163 518 280 267 552\n",
      " 436 688 674 333 457  81  15 279 183 519 484 420 264 233 257 396  86 447\n",
      "  82   5  61 276 143  70 110 479 380 324 504 222 582 179 244 490 597 682\n",
      "  93   3 684 198 109  28 485 144 556 634 221 114   1 611 647 373 103  50\n",
      " 615 390 214 654 557 282 505 547 251 226 388 266 598  35 270 671 413 408\n",
      " 529 123 224 553 178  95 339  94 230 347 478 379 588 337 220 340 437 483\n",
      " 416 247  10 243 246 187  37 391 540 185 100 320 535 329 506 119 132 184\n",
      " 590 521 631 680 315 356 606 383 202 325 139 305 206 127]\n",
      "TEST: [242 153 579 147 482 666 460 510 531 115 215  56 219 468 441 137 190 208\n",
      " 167  54 134 568 107 629  66 462 250 472 646 664 589 151 170 591 592 489\n",
      " 668 530 497 234 596 551 195 295 302 640 488 549 561 580 269 630 520 172\n",
      " 562   2  19 286 253  71 298 158 583 573 507 326 328  34 599 467  26 539\n",
      " 203 238  24 622 284 576 661   6 262 399 338 418 414  21 639 602 476 660\n",
      "  85 477 486 690 663 613 604 448 232 532  99 564 677 384 240 469 292 534\n",
      " 678 314 368 650 516 683 341 637 454 237 223 430  96 159 508 335 261 217\n",
      "  97  58 155  40 133  59 624 498 493 393 515 402  68]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         2\n",
      "          4       0.33      1.00      0.50         1\n",
      "          5       0.25      1.00      0.40         1\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       0.50      1.00      0.67         1\n",
      "          8       0.50      1.00      0.67         1\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.50      1.00      0.67         1\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       0.00      0.00      0.00         2\n",
      "         15       0.50      1.00      0.67         1\n",
      "         16       0.33      1.00      0.50         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.50      1.00      0.67         1\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       0.00      0.00      0.00         2\n",
      "         25       0.33      1.00      0.50         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       0.25      1.00      0.40         1\n",
      "         28       0.00      0.00      0.00         2\n",
      "         29       0.00      0.00      0.00         2\n",
      "         30       0.33      1.00      0.50         1\n",
      "         31       0.50      1.00      0.67         1\n",
      "         32       0.50      1.00      0.67         1\n",
      "         33       0.50      1.00      0.67         1\n",
      "         34       0.00      0.00      0.00         1\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.00      0.00      0.00         1\n",
      "         37       0.25      1.00      0.40         1\n",
      "         38       0.00      0.00      0.00         2\n",
      "         39       0.33      1.00      0.50         1\n",
      "         40       0.33      1.00      0.50         1\n",
      "         41       0.20      1.00      0.33         1\n",
      "         42       0.33      1.00      0.50         1\n",
      "         43       0.00      0.00      0.00         2\n",
      "         44       0.50      1.00      0.67         1\n",
      "         45       1.00      1.00      1.00         1\n",
      "         46       0.50      1.00      0.67         1\n",
      "         47       0.00      0.00      0.00         2\n",
      "         48       0.25      1.00      0.40         1\n",
      "         49       0.50      1.00      0.67         1\n",
      "         50       0.00      0.00      0.00         2\n",
      "         51       0.50      1.00      0.67         1\n",
      "         52       0.50      1.00      0.67         1\n",
      "         53       0.17      1.00      0.29         1\n",
      "         54       0.20      1.00      0.33         1\n",
      "         55       0.20      1.00      0.33         1\n",
      "         56       0.33      1.00      0.50         1\n",
      "         57       0.50      1.00      0.67         1\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         61       0.50      1.00      0.67         1\n",
      "         62       0.00      0.00      0.00         2\n",
      "         63       0.00      0.00      0.00         2\n",
      "         64       1.00      1.00      1.00         1\n",
      "         65       0.00      0.00      0.00         2\n",
      "         66       0.50      1.00      0.67         1\n",
      "         67       0.00      0.00      0.00         2\n",
      "         68       1.00      1.00      1.00         1\n",
      "         69       0.00      0.00      0.00         2\n",
      "         70       0.00      0.00      0.00         2\n",
      "         71       0.00      0.00      0.00         2\n",
      "         72       0.50      1.00      0.67         1\n",
      "         73       0.50      1.00      0.67         1\n",
      "         74       0.00      0.00      0.00         2\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.00      0.00      0.00         2\n",
      "         77       1.00      1.00      1.00         1\n",
      "         78       0.33      1.00      0.50         1\n",
      "         79       1.00      1.00      1.00         1\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.33      1.00      0.50         1\n",
      "         82       0.14      1.00      0.25         1\n",
      "         83       0.00      0.00      0.00         1\n",
      "         84       0.00      0.00      0.00         2\n",
      "         85       0.00      0.00      0.00         2\n",
      "         86       1.00      1.00      1.00         1\n",
      "         87       0.00      0.00      0.00         2\n",
      "         88       0.00      0.00      0.00         2\n",
      "         89       0.00      0.00      0.00         2\n",
      "         90       0.00      0.00      0.00         1\n",
      "         91       0.33      1.00      0.50         1\n",
      "         92       0.00      0.00      0.00         2\n",
      "         93       0.00      0.00      0.00         2\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       0.20      1.00      0.33         1\n",
      "         96       0.25      1.00      0.40         1\n",
      "         97       0.25      1.00      0.40         1\n",
      "         98       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.20      0.38      0.24       139\n",
      "\n",
      "\n",
      "Fehler in FUN(X[[i]], ...) : \n",
      "  nur für einen data frame definiert, mit nur nummerischen Variablen\n",
      "{   'AUC_R': 16.0,\n",
      "    'Accuracy': 0.9784172661870504,\n",
      "    'Error rate': 0.02158273381294964,\n",
      "    'False negative rate': 0.021739130434782608,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 0.25,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9712230215827338,\n",
      "    'Sensitivity (true positives rate)': 0.9782608695652174,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 0.4,\n",
      "    'kappa': 0.3930131004366815}\n",
      "###################### Training Fold:  5  #################\n",
      "TRAIN: [556 165  54 370 309 193 269 229 491  59 492 565 362 418 612 128 606 149\n",
      " 422  98 241 381 304 635 604 336 654 261 355 231 187 200 475 199 463 522\n",
      "  49 639 472 649 120 508 480 420 670 296  73  94 108 212 435 392 317  63\n",
      " 308 663  83 145 218 223 593 653  62 268 678 243 146 470   2 102 173 235\n",
      " 679 281 582   7   5 575 270 148 385 485 659  65  95 421 150 303 484 330\n",
      "  96 374 397  22 517 578 618 251 534 464 162  80  21   6 380 400 561  52\n",
      " 544 538  61 401 278 550 154 334   0 673 191 127 572 230 256 142 629 121\n",
      " 430 252 341 225   9 131 531 425  48 141 207 176 255  41 410 373 454 215\n",
      " 633 224 617 376 195 101 242  10 417 349  75 153 332 540 358 494 286 487\n",
      " 601  33 610 329 394 169  32  53  97 597 434 583  35 357 289 112 322 406\n",
      " 548 436 448   3 151  68 579 626 284 384 688 213 509 369  86 478  84 490\n",
      " 361 545 320 371  24 574 432  71 685 192 458 613 294 553 117 249  42 446\n",
      " 404 290  55 433 291 305 277 378 280 262 640  56 253  79 363 462 178 163\n",
      " 377 523 431 236  82 690 468  99 558 315 155 573 596 311 569 398 393 202\n",
      " 266   8 209 520 450 622 403 474 476 135 681 125 528 619 563 570 605 647\n",
      " 632 671 429 246   1 160 143 318  45 396  19 204 107 293 354 222  40  87\n",
      " 300 598  34   4 510 372 625 189 588 552  93  69  50 683 161  31  91 519\n",
      " 658 323 196 333 411 516 201 650  57 496 486 527 460 167 656  66 682 170\n",
      " 382 287 525 264 226 676 174 655 636 592 567 316 680 405 171 689 182 466\n",
      " 437 118 481 345 144 389 489 521 352 473 488 221 383 185 591 438 628 183\n",
      " 402  58 513 652 214 325 576 177 340 506 335 667 147 298 134 511 452  76\n",
      " 122 589 638 217 611  43 560 267 307 138 512  25  74 453 301 203  37 186\n",
      " 282  16  36 530 238  29 337 559  90 424  17 328 367 661 660 164 119 419\n",
      " 599 637 132 387 562 498 467 455 537 136 220  46 351  12 643 529 541  14\n",
      " 482 532 179 152 276 365 590 339 391  30 245 273  81  23  89 181 233 662\n",
      " 190 299 368 465 324  18 237 240 443 110 197 686 668 664  92 426 313 338\n",
      " 271 580 439  15 312 227  39 263 103 156 295 188 416 168 423 500 205  38\n",
      " 247 123 551 595 571 547 524 445 360 507  67 275  72 447 210 440 444 140\n",
      " 514 675 413 302 586 175 594 505 364 228 457  28 581 539 456 265 137 657\n",
      " 342 115  11 166 194 319 669 543 584 388  88 133 642 607 677 620 344 615\n",
      " 614 100 461 648 158 409 350 379 327 285 666 343 274 546]\n",
      "TEST: [ 60 310 124 427 630 180 549 111 483 139 542 321 346 631 106 515 347 260\n",
      " 623 250 258 587 244 624 331 105 535 172 297 159 109 257 602 557 412 198\n",
      " 415  13 503 501 130 356 326  26 634 407 459 554 609 672 219 471 684 651\n",
      " 641 451 603 254 518 414 449 600  70 279  44 526 113 441 116 129 442 585\n",
      " 479 353  51  20 184 577 428 248 208 502 395 314  47 627 104 211 386 114\n",
      "  78 292 674 497 692 272 234 359 239  85 477 533 232  27 621 568  77 564\n",
      " 665 646 504 555 608  64 288 536 691 157 495 645 216 206 566 126 493 259\n",
      " 616 469 366 348 375 408 306 399 390 687 644 283 499]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:185: RRuntimeWarning: Fehler in FUN(X[[i]], ...) : \n",
      "  nur für einen data frame definiert, mit nur nummerischen Variablen\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         1\n",
      "          1       0.33      1.00      0.50         1\n",
      "          2       0.50      1.00      0.67         1\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         2\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       0.00      0.00      0.00         2\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.25      1.00      0.40         1\n",
      "         13       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         2\n",
      "         15       0.33      1.00      0.50         1\n",
      "         16       0.50      1.00      0.67         1\n",
      "         17       0.14      1.00      0.25         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       0.50      1.00      0.67         1\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         1\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.33      1.00      0.50         1\n",
      "         29       0.00      0.00      0.00         2\n",
      "         30       0.00      0.00      0.00         2\n",
      "         31       0.00      0.00      0.00         1\n",
      "         32       0.00      0.00      0.00         2\n",
      "         33       0.00      0.00      0.00         2\n",
      "         34       1.00      1.00      1.00         1\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.00      0.00      0.00         2\n",
      "         37       0.25      1.00      0.40         1\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.17      1.00      0.29         1\n",
      "         40       0.00      0.00      0.00         2\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00         2\n",
      "         43       0.33      1.00      0.50         1\n",
      "         44       0.00      0.00      0.00         2\n",
      "         45       0.50      1.00      0.67         1\n",
      "         46       0.00      0.00      0.00         1\n",
      "         47       1.00      1.00      1.00         1\n",
      "         48       0.50      1.00      0.67         1\n",
      "         49       0.00      0.00      0.00         2\n",
      "         50       0.50      1.00      0.67         1\n",
      "         51       0.00      0.00      0.00         2\n",
      "         52       0.00      0.00      0.00         2\n",
      "         53       0.50      1.00      0.67         1\n",
      "         54       0.17      1.00      0.29         1\n",
      "         55       0.50      1.00      0.67         1\n",
      "         56       0.25      1.00      0.40         1\n",
      "         57       0.33      1.00      0.50         1\n",
      "         58       0.00      0.00      0.00         2\n",
      "         59       0.00      0.00      0.00         2\n",
      "         60       0.00      0.00      0.00         2\n",
      "         61       1.00      1.00      1.00         1\n",
      "         62       0.50      1.00      0.67         1\n",
      "         63       0.00      0.00      0.00         2\n",
      "         64       0.50      1.00      0.67         1\n",
      "         65       0.50      1.00      0.67         1\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       0.50      1.00      0.67         1\n",
      "         68       0.00      0.00      0.00         1\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       0.50      1.00      0.67         1\n",
      "         71       0.25      1.00      0.40         1\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       0.25      1.00      0.40         1\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.00      0.00      0.00         2\n",
      "         77       0.00      0.00      0.00         2\n",
      "         78       0.25      1.00      0.40         1\n",
      "         79       0.00      0.00      0.00         2\n",
      "         80       1.00      1.00      1.00         1\n",
      "         81       0.11      1.00      0.20         1\n",
      "         82       0.00      0.00      0.00         2\n",
      "         83       0.50      1.00      0.67         1\n",
      "         84       1.00      1.00      1.00         1\n",
      "         85       0.00      0.00      0.00         2\n",
      "         86       0.00      0.00      0.00         2\n",
      "         87       0.00      0.00      0.00         2\n",
      "         88       0.00      0.00      0.00         2\n",
      "         89       0.25      1.00      0.40         1\n",
      "         90       1.00      1.00      1.00         1\n",
      "         91       0.00      0.00      0.00         2\n",
      "         92       0.50      1.00      0.67         1\n",
      "         93       0.00      0.00      0.00         1\n",
      "         94       0.33      1.00      0.50         1\n",
      "         95       0.00      0.00      0.00         2\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       0.17      1.00      0.29         1\n",
      "         98       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.22      0.37      0.26       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 138   0\n",
       "   N   0   1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 2.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.0072463768115942,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.9928057553956835,\n",
      "    'Rate of positive predictions': 0.9928057553956835,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n",
      "###################### Validation #################\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         3\n",
      "          3       1.00      1.00      1.00         3\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      1.00      1.00         3\n",
      "          8       0.75      1.00      0.86         3\n",
      "          9       1.00      1.00      1.00         3\n",
      "         10       1.00      0.67      0.80         3\n",
      "         11       1.00      0.67      0.80         3\n",
      "         12       1.00      1.00      1.00         3\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       0.60      1.00      0.75         3\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.75      1.00      0.86         3\n",
      "         17       1.00      0.67      0.80         3\n",
      "         18       1.00      0.67      0.80         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         3\n",
      "         21       1.00      1.00      1.00         3\n",
      "         22       1.00      0.67      0.80         3\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         3\n",
      "         26       1.00      0.33      0.50         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       0.33      0.33      0.33         3\n",
      "         29       1.00      0.67      0.80         3\n",
      "         30       0.75      1.00      0.86         3\n",
      "         31       1.00      0.33      0.50         3\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         3\n",
      "         34       1.00      0.33      0.50         3\n",
      "         35       1.00      1.00      1.00         3\n",
      "         36       1.00      0.67      0.80         3\n",
      "         37       0.75      1.00      0.86         3\n",
      "         38       1.00      0.67      0.80         3\n",
      "         39       1.00      1.00      1.00         3\n",
      "         40       0.50      1.00      0.67         3\n",
      "         41       1.00      1.00      1.00         3\n",
      "         42       1.00      1.00      1.00         3\n",
      "         43       1.00      1.00      1.00         3\n",
      "         44       1.00      1.00      1.00         3\n",
      "         45       1.00      1.00      1.00         3\n",
      "         46       1.00      0.67      0.80         3\n",
      "         47       1.00      1.00      1.00         3\n",
      "         48       1.00      1.00      1.00         3\n",
      "         49       1.00      1.00      1.00         3\n",
      "         50       1.00      0.67      0.80         3\n",
      "         51       0.75      1.00      0.86         3\n",
      "         52       0.60      1.00      0.75         3\n",
      "         53       0.75      1.00      0.86         3\n",
      "         54       0.75      1.00      0.86         3\n",
      "         55       1.00      1.00      1.00         3\n",
      "         56       1.00      1.00      1.00         3\n",
      "         57       1.00      1.00      1.00         3\n",
      "         58       0.67      0.67      0.67         3\n",
      "         59       0.75      1.00      0.86         3\n",
      "         60       1.00      0.67      0.80         3\n",
      "         61       1.00      0.67      0.80         3\n",
      "         62       1.00      1.00      1.00         3\n",
      "         63       1.00      0.67      0.80         3\n",
      "         64       1.00      1.00      1.00         3\n",
      "         65       1.00      1.00      1.00         3\n",
      "         66       1.00      1.00      1.00         3\n",
      "         67       0.75      1.00      0.86         3\n",
      "         68       0.60      1.00      0.75         3\n",
      "         69       1.00      0.33      0.50         3\n",
      "         70       1.00      1.00      1.00         3\n",
      "         71       0.50      0.67      0.57         3\n",
      "         72       1.00      1.00      1.00         3\n",
      "         73       1.00      1.00      1.00         3\n",
      "         74       1.00      1.00      1.00         3\n",
      "         75       1.00      1.00      1.00         3\n",
      "         76       0.75      1.00      0.86         3\n",
      "         77       1.00      1.00      1.00         3\n",
      "         78       1.00      1.00      1.00         3\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       1.00      0.67      0.80         3\n",
      "         81       0.60      1.00      0.75         3\n",
      "         82       1.00      1.00      1.00         3\n",
      "         83       1.00      0.33      0.50         3\n",
      "         84       1.00      1.00      1.00         3\n",
      "         85       1.00      0.33      0.50         3\n",
      "         86       0.50      1.00      0.67         3\n",
      "         87       1.00      1.00      1.00         3\n",
      "         88       1.00      1.00      1.00         3\n",
      "         89       1.00      1.00      1.00         3\n",
      "         90       1.00      1.00      1.00         3\n",
      "         91       1.00      1.00      1.00         3\n",
      "         92       0.75      1.00      0.86         3\n",
      "         93       1.00      1.00      1.00         3\n",
      "         94       1.00      1.00      1.00         3\n",
      "         95       1.00      0.67      0.80         3\n",
      "         96       1.00      1.00      1.00         3\n",
      "         97       0.75      1.00      0.86         3\n",
      "         98       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.93      0.90      0.89       297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    results\n",
       "data   J   N\n",
       "   J 294   0\n",
       "   N   0   3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AUC_R': 1.0,\n",
      "    'Accuracy': 1.0,\n",
      "    'Error rate': 0.0,\n",
      "    'False negative rate': 0.0,\n",
      "    'False positive rate': 0.0,\n",
      "    'Lift value': 1.010204081632653,\n",
      "    'Precision J': 1.0,\n",
      "    'Precision N': 1.0,\n",
      "    'Rate of negative predictions': 0.98989898989899,\n",
      "    'Rate of positive predictions': 0.98989898989899,\n",
      "    'Sensitivity (true positives rate)': 1.0,\n",
      "    'Specificity (true negatives rate)': 1.0,\n",
      "    'f1_R': 1.0,\n",
      "    'kappa': 1.0}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "evaluateCV(X, y, clf, '01_rf10', allResultsOfModels, gSeed)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "evaluateCV(X, y, clf, '01_rf100', allResultsOfModels, gSeed)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "evaluateCV(X, y, clf, '01_rf1000', allResultsOfModels, gSeed)\n",
    "\n",
    "clf = SVC()\n",
    "evaluateCV(X, y, clf, '01_rf', allResultsOfModels, gSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# komisch - das crasht bei mir\n",
    "#clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1)\n",
    "#evaluateCV(X, y, clf, '02_lr', allResultsOfModels, gSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for res in allResultsOfModels:\n",
    "    results.append(res.__dict__)\n",
    "\n",
    "l = list(map(flatten_dict, results))\n",
    "results = pd.DataFrame.from_dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC_R_mean</th>\n",
       "      <th>AUC_R_std</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Error rate_mean</th>\n",
       "      <th>Error rate_std</th>\n",
       "      <th>False negative rate_mean</th>\n",
       "      <th>False negative rate_std</th>\n",
       "      <th>False positive rate_mean</th>\n",
       "      <th>False positive rate_std</th>\n",
       "      <th>...</th>\n",
       "      <th>Rate of positive predictions_mean</th>\n",
       "      <th>Rate of positive predictions_std</th>\n",
       "      <th>Sensitivity (true positives rate)_mean</th>\n",
       "      <th>Sensitivity (true positives rate)_std</th>\n",
       "      <th>Specificity (true negatives rate)_mean</th>\n",
       "      <th>Specificity (true negatives rate)_std</th>\n",
       "      <th>f1_R_mean</th>\n",
       "      <th>f1_R_std</th>\n",
       "      <th>kappa_mean</th>\n",
       "      <th>kappa_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991367</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991367</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf10</th>\n",
       "      <td>6.6</td>\n",
       "      <td>10.591270</td>\n",
       "      <td>0.995683</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987050</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.995652</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.831597</td>\n",
       "      <td>0.238202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>8.8</td>\n",
       "      <td>6.723095</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.250998</td>\n",
       "      <td>0.555023</td>\n",
       "      <td>0.253877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AUC_R_mean  AUC_R_std  Accuracy_mean  Accuracy_std  \\\n",
       "modelName                                                       \n",
       "rf100             1.0   0.000000       1.000000      0.000000   \n",
       "rf1000            1.0   0.000000       1.000000      0.000000   \n",
       "rf10              6.6  10.591270       0.995683      0.006435   \n",
       "rf                8.8   6.723095       0.985612      0.008811   \n",
       "\n",
       "           Error rate_mean  Error rate_std  False negative rate_mean  \\\n",
       "modelName                                                              \n",
       "rf100             0.000000        0.000000                  0.000000   \n",
       "rf1000            0.000000        0.000000                  0.000000   \n",
       "rf10              0.004317        0.006435                  0.004348   \n",
       "rf                0.014388        0.008811                  0.014493   \n",
       "\n",
       "           False negative rate_std  False positive rate_mean  \\\n",
       "modelName                                                      \n",
       "rf100                     0.000000                       0.0   \n",
       "rf1000                    0.000000                       0.0   \n",
       "rf10                      0.006481                       0.0   \n",
       "rf                        0.008875                       0.0   \n",
       "\n",
       "           False positive rate_std    ...      \\\n",
       "modelName                             ...       \n",
       "rf100                          0.0    ...       \n",
       "rf1000                         0.0    ...       \n",
       "rf10                           0.0    ...       \n",
       "rf                             0.0    ...       \n",
       "\n",
       "           Rate of positive predictions_mean  \\\n",
       "modelName                                      \n",
       "rf100                               0.991367   \n",
       "rf1000                              0.991367   \n",
       "rf10                                0.987050   \n",
       "rf                                  0.978417   \n",
       "\n",
       "           Rate of positive predictions_std  \\\n",
       "modelName                                     \n",
       "rf100                              0.003217   \n",
       "rf1000                             0.003217   \n",
       "rf10                               0.006019   \n",
       "rf                                 0.008811   \n",
       "\n",
       "           Sensitivity (true positives rate)_mean  \\\n",
       "modelName                                           \n",
       "rf100                                    1.000000   \n",
       "rf1000                                   1.000000   \n",
       "rf10                                     0.995652   \n",
       "rf                                       0.985507   \n",
       "\n",
       "           Sensitivity (true positives rate)_std  \\\n",
       "modelName                                          \n",
       "rf100                                   0.000000   \n",
       "rf1000                                  0.000000   \n",
       "rf10                                    0.006481   \n",
       "rf                                      0.008875   \n",
       "\n",
       "           Specificity (true negatives rate)_mean  \\\n",
       "modelName                                           \n",
       "rf100                                         1.0   \n",
       "rf1000                                        1.0   \n",
       "rf10                                          1.0   \n",
       "rf                                            1.0   \n",
       "\n",
       "           Specificity (true negatives rate)_std  f1_R_mean  f1_R_std  \\\n",
       "modelName                                                               \n",
       "rf100                                        0.0   1.000000  0.000000   \n",
       "rf1000                                       0.0   1.000000  0.000000   \n",
       "rf10                                         0.0   0.833333  0.235702   \n",
       "rf                                           0.0   0.560000  0.250998   \n",
       "\n",
       "           kappa_mean  kappa_std  \n",
       "modelName                         \n",
       "rf100        1.000000   0.000000  \n",
       "rf1000       1.000000   0.000000  \n",
       "rf10         0.831597   0.238202  \n",
       "rf           0.555023   0.253877  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = results[results.typeOfRun != 'validation']\n",
    "overview = train_res.groupby([train_res.modelName.str.split('_').str[1]]).describe().unstack(\n",
    "    fill_value=0).loc[:,\n",
    "           pd.IndexSlice[:, ['mean', 'std']]]#[['kappa', 'Lift value', 'False positive rate', 'False negative rate']]\n",
    "overview.columns = ['{0[0]}_{0[1]}'.format(tup) for tup in overview.columns]\n",
    "overview.sort_values('kappa_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
