{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import skutils\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 47\n",
    "\n",
    "# Use ggplot style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1      49\n",
       "2      65\n",
       "3      94\n",
       "4      84\n",
       "5      40\n",
       "6      54\n",
       "7      78\n",
       "8      53\n",
       "9      89\n",
       "10     98\n",
       "11     16\n",
       "12     74\n",
       "13     50\n",
       "14     58\n",
       "15     31\n",
       "16     43\n",
       "17      4\n",
       "18     75\n",
       "19     44\n",
       "20     83\n",
       "21     84\n",
       "22     13\n",
       "23     66\n",
       "24     15\n",
       "25      6\n",
       "26     73\n",
       "27     22\n",
       "28     73\n",
       "29     31\n",
       "       ..\n",
       "960    85\n",
       "961    89\n",
       "962    94\n",
       "963    45\n",
       "964    48\n",
       "965    86\n",
       "966    81\n",
       "967    14\n",
       "968     4\n",
       "969    77\n",
       "970    56\n",
       "971    82\n",
       "972     2\n",
       "973    85\n",
       "974    70\n",
       "975    88\n",
       "976     0\n",
       "977    75\n",
       "978    14\n",
       "979    86\n",
       "980    81\n",
       "981    97\n",
       "982    70\n",
       "983    72\n",
       "984    34\n",
       "985    40\n",
       "986     5\n",
       "987    11\n",
       "988    78\n",
       "989    50\n",
       "Name: species, dtype: int8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big = train\n",
    "\n",
    "big.species = big.species.astype('category')\n",
    "big.species = big.species.cat.codes\n",
    "\n",
    "# big = pd.get_dummies(big, sparse=True)\n",
    "\n",
    "big.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    ID = data.id\n",
    "    X = data.drop(['species', 'id'], axis=1)\n",
    "    y = data['species']\n",
    "    return ID, X, y\n",
    "\n",
    "ID, X, y = transform(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addZeroColumn(df, colName):\n",
    "    df.loc[df[colName] < 0.01, colName + '_is_small'] = 1\n",
    "    df[colName + '_is_small'].fillna(0, inplace=True)\n",
    "\n",
    "def addZeroColumns(df, colBaseName):\n",
    "    for n in range(1,65):\n",
    "        addZeroColumn(df, colBaseName + str(n))\n",
    "        \n",
    "addZeroColumns(X, 'margin')\n",
    "addZeroColumns(X, 'texture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, recall_score, cohen_kappa_score, auc, make_scorer, average_precision_score, f1_score, brier_score_loss, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifiers = {\n",
    "        \"LR_1\": { \"f\": LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1, C=1, penalty='l2') },\n",
    "        \"LR_2\": { \"f\": LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1, C=0.8, penalty='l2') },\n",
    "        \"LR_3\": { \"f\": LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1, C=1.2, penalty='l2') },\n",
    "        \"LR_4\": { \"f\": LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1, C=10, penalty='l2') },\n",
    "        \"LR_5\": { \"f\": LogisticRegression(solver='newton-cg', multi_class='multinomial', n_jobs=-1, C=1, penalty='l2') },\n",
    "        \"LR_6\": { \"f\": LogisticRegression(solver='newton-cg', multi_class='multinomial', n_jobs=-1, C=0.8, penalty='l2') },\n",
    "        \"LR_7\": { \"f\": LogisticRegression(solver='newton-cg', multi_class='multinomial', n_jobs=-1, C=1.2, penalty='l2') },\n",
    "        \"LR_8\": { \"f\": LogisticRegression(solver='newton-cg', multi_class='multinomial', n_jobs=-1, C=10, penalty='l2') },\n",
    "        \"RF_1\": { \"f\": RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini', min_samples_leaf=1) },\n",
    "        \"RF_2\": { \"f\": RandomForestClassifier(n_estimators=10, n_jobs=-1, criterion='gini', min_samples_leaf=1) },\n",
    "        \"RF_3\": { \"f\": RandomForestClassifier(n_estimators=20, n_jobs=-1, criterion='gini', min_samples_leaf=1) },\n",
    "        \"RF_4\": { \"f\": RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini', min_samples_leaf=1) },\n",
    "        \"RF_5\": { \"f\": RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini', min_samples_leaf=3) },\n",
    "        \"RF_6\": { \"f\": RandomForestClassifier(n_estimators=10, n_jobs=-1, criterion='gini', min_samples_leaf=3) },\n",
    "        \"RF_7\": { \"f\": RandomForestClassifier(n_estimators=20, n_jobs=-1, criterion='gini', min_samples_leaf=3) },\n",
    "        \"RF_8\": { \"f\": RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini', min_samples_leaf=3) },\n",
    "        \"RF_9\": { \"f\": RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy', min_samples_leaf=1) },\n",
    "        \"RF_A\": { \"f\": RandomForestClassifier(n_estimators=10, n_jobs=-1, criterion='entropy', min_samples_leaf=1) },\n",
    "        \"RF_B\": { \"f\": RandomForestClassifier(n_estimators=20, n_jobs=-1, criterion='entropy', min_samples_leaf=1) },\n",
    "        \"RF_C\": { \"f\": RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy', min_samples_leaf=1) },\n",
    "} \n",
    "\n",
    "classifiers = {\n",
    "    \"LR_std\": { \"f\": Pipeline([\n",
    "                ('scaling', StandardScaler()),\n",
    "                ('estimator', LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1))\n",
    "            ]) },\n",
    "    \"RF\": { \"f\": RandomForestClassifier(n_estimators=100, n_jobs=-1) },\n",
    "    \n",
    "    \"LR_std\": { \"f\": Pipeline([\n",
    "                ('scaling', StandardScaler()),\n",
    "                ('estimator', LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1))\n",
    "            ]) },\n",
    "    \"LR_mm\": { \"f\": Pipeline([\n",
    "                ('scaling', MinMaxScaler()),\n",
    "                ('estimator', LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1))\n",
    "            ]) },\n",
    "    \"LR_rob\": { \"f\": Pipeline([\n",
    "                ('scaling', RobustScaler()),\n",
    "                ('estimator', LogisticRegression(solver='lbfgs', multi_class='multinomial', n_jobs=-1))\n",
    "            ]) },\n",
    "    \"RF_std\": { \"f\": Pipeline([\n",
    "                ('scaling', StandardScaler()),\n",
    "                ('estimator', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n",
    "            ]) },\n",
    "    \"RF_mm\": { \"f\": Pipeline([\n",
    "                ('scaling', MinMaxScaler()),\n",
    "                ('estimator', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n",
    "            ]) },\n",
    "    \"RF_rob\": { \"f\": Pipeline([\n",
    "                ('scaling', RobustScaler()),\n",
    "                ('estimator', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n",
    "            ]) },\n",
    "}    \n",
    "\n",
    "measures = {\n",
    "    'pre': precision_score,\n",
    "    'rec': recall_score,\n",
    "    'acc': accuracy_score,\n",
    "    'ck': cohen_kappa_score,\n",
    "    'f1': f1_score,\n",
    "}\n",
    "\n",
    "sizes = []\n",
    "for i in range(1,9):\n",
    "    sizes.append(0.1 + 0.1 * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def test_split(size):\n",
    "    sss = StratifiedShuffleSplit(10, test_size=size, random_state=seed)\n",
    "    clfs = copy.deepcopy(classifiers)\n",
    "    \n",
    "    for clf in clfs.keys(): \n",
    "        c = clfs[clf]   \n",
    "        for meas in measures.keys():\n",
    "            c[meas] = []\n",
    "\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        for clf in clfs.keys():                    \n",
    "            c = clfs[clf]    \n",
    "            c[\"f\"].fit(X_train, y_train)\n",
    "            y_pred = np.asarray(c[\"f\"].predict(X_test))\n",
    "\n",
    "            for meas in measures.keys():\n",
    "                m = measures[meas]\n",
    "\n",
    "                if (meas != 'ck' and meas != 'acc' and meas != 'br'):\n",
    "                    c[meas].append(m(y_test, y_pred, average='macro'))\n",
    "                elif (meas == 'll'):\n",
    "                    c[meas].append(m(y_test, y_pred, labels=y_test))\n",
    "                else:\n",
    "                    c[meas].append(m(y_test, y_pred))\n",
    "    \n",
    "    return clfs\n",
    "               \n",
    "cl = []\n",
    "    \n",
    "for s in sizes:\n",
    "    cl.append(test_split(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    results = pd.DataFrame(columns=measures)\n",
    "    \n",
    "    for i in range(0,len(cl)):\n",
    "        res = [np.mean(cl[i][model][measure]) for measure in measures.keys()]\n",
    "        results.loc[sizes[i]] = res\n",
    "\n",
    "    figsize(10, 5)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ind = np.arange(results.shape[0])\n",
    "    width = 0.2\n",
    "    l = ax.plot(ind, results, \"-o\")\n",
    "    plt.legend(iter(l), results.columns.tolist(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlim([-0.25, ind[-1]+.25])\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(results.index)\n",
    "    \n",
    "    if (model.startswith(\"LR\")):\n",
    "        ax.set_ylim([0.65,1])\n",
    "    else:\n",
    "        ax.set_ylim([0,1])\n",
    "    plt.title(model)\n",
    "    \n",
    "    plt.savefig(\"plots/\" + model + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_param(classifier):\n",
    "    results = pd.DataFrame(columns=measures)\n",
    "\n",
    "    for model in classifiers.keys():\n",
    "        if (model.startswith(classifier)):\n",
    "            res = [np.mean(cl[2][model][measure]) for measure in measures.keys()]\n",
    "            results.loc[model] = res\n",
    "\n",
    "    results = results.sort_index()\n",
    "    \n",
    "    figsize(10, 5)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ind = np.arange(results.shape[0])\n",
    "    width = 0.2\n",
    "    l = ax.plot(ind, results, \"-o\")\n",
    "    plt.legend(iter(l), results.columns.tolist(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlim([-0.25, ind[-1]+.25])\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(results.index)\n",
    "    plt.title(classifier)\n",
    "\n",
    "    plt.savefig(\"plots/\" + classifier + \"_compare_param.png\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_param(\"LR\")\n",
    "plot_param(\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
