{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevie/Develop/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import skutils\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Imputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, classification_report, recall_score, cohen_kappa_score, auc, make_scorer, average_precision_score, f1_score, brier_score_loss, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "seed = 47\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "big = pd.read_csv('train.csv')\n",
    "\n",
    "big.species = big.species.astype('category')\n",
    "big.species = big.species.cat.codes\n",
    "\n",
    "def transform(data):\n",
    "    ID = data.id\n",
    "    X = data.drop(['species', 'id'], axis=1)\n",
    "    y = data['species']\n",
    "    return ID, X, y\n",
    "\n",
    "ID, X, y = transform(big)\n",
    "\n",
    "def addZeroColumn(df, colName):\n",
    "    df.loc[df[colName] < 0.01, colName + '_is_small'] = 1\n",
    "    df[colName + '_is_small'].fillna(0, inplace=True)\n",
    "\n",
    "def addZeroColumns(df, colBaseName):\n",
    "    for n in range(1,65):\n",
    "        addZeroColumn(df, colBaseName + str(n))\n",
    "        \n",
    "addZeroColumns(X, 'margin')\n",
    "addZeroColumns(X, 'texture')\n",
    "\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, stratify=y, test_size=0.1)\n",
    "\n",
    "X = X.sort_index()\n",
    "y = y.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (1) + (2)\n",
    "\n",
    "def remove_values_attribute(df, attribute, percentage):\n",
    "    df = df.copy()\n",
    "    df.loc[df.sample(n=int(percentage * df.shape[0]), random_state=seed).index, attribute] = None\n",
    "    return df\n",
    "    \n",
    "def remove_values(df, percentage):\n",
    "    np.random.seed(seed)\n",
    "    df = df.copy()\n",
    "    for i in df.sample(n=int(percentage * df.shape[0]), random_state=seed).index:\n",
    "        j = np.random.randint(df.shape[1])\n",
    "        df.loc[i,df.columns[j]] = None\n",
    "    return df\n",
    "    \n",
    "low = 0.1\n",
    "high = 0.6\n",
    "\n",
    "Xn = {\n",
    "    'margin5_low': {\n",
    "        'X': {\n",
    "            'original': remove_values_attribute(X, 'margin5', low)\n",
    "        }\n",
    "    },\n",
    "    'margin5_high': {\n",
    "        'X': {\n",
    "            'original': remove_values_attribute(X, 'margin5', high)\n",
    "        }\n",
    "    },\n",
    "    'shape1_low': {\n",
    "        'X': {\n",
    "            'original': remove_values_attribute(X, 'shape1', low)\n",
    "        }\n",
    "    },\n",
    "    'shape1_high': {\n",
    "        'X': {\n",
    "            'original': remove_values_attribute(X, 'shape1', high)\n",
    "        }\n",
    "    },\n",
    "    'all_low': {\n",
    "        'X': {\n",
    "            'original': remove_values(X, low)\n",
    "        }\n",
    "    },\n",
    "    'all_high':{\n",
    "        'X': {\n",
    "            'original': remove_values(X, high)\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (3)\n",
    "\n",
    "strategies = ['ignore', 'totalmean', 'classmean']\n",
    "\n",
    "def ignore_missing(df):\n",
    "    return df.dropna(axis=1)\n",
    "\n",
    "def replace_by_totalmean(df):\n",
    "    return pd.DataFrame(Imputer(axis=1).fit_transform(df))\n",
    "\n",
    "def replace_by_classmean(X, y):    \n",
    "    df = pd.concat([y,X], axis=1)\n",
    "    \n",
    "    for col in X.columns[X.isnull().any()].tolist():\n",
    "        grouped = df.groupby(['species'])[col].mean().to_frame().reset_index()\n",
    "        \n",
    "        df['index'] = df.index\n",
    "        df = df.merge(grouped, left_on='species', right_on='species', how='inner')\n",
    "        df = df.set_index('index')\n",
    "        df = df.sort_index()\n",
    "        df.index.name = None\n",
    "\n",
    "        df[col] = df[col + '_x']\n",
    "        df[col] = df[col].fillna(df[col + '_y']).fillna(0) # zero if classmean is nan\n",
    "        df = df.drop([col + '_x', col + '_y'], axis=1)        \n",
    "    \n",
    "    return df.drop('species', axis=1)\n",
    "\n",
    "for k in Xn.keys():\n",
    "    Xi = Xn[k]['X']\n",
    "    Xi['ignore'] = ignore_missing(Xi['original'])\n",
    "    Xi['totalmean'] = replace_by_totalmean(Xi['original'])\n",
    "    Xi['classmean'] = replace_by_classmean(Xi['original'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "measures = {\n",
    "    'pre': precision_score,\n",
    "    'rec': recall_score,\n",
    "    'acc': accuracy_score,\n",
    "    'ck': cohen_kappa_score,\n",
    "    'f1': f1_score,\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"LR\": { \"f\": Pipeline([\n",
    "                ('scaling', StandardScaler()),\n",
    "                ('estimator', LogisticRegression(solver='lbfgs', multi_class='multinomial', C=10, n_jobs=-1))\n",
    "            ]) },\n",
    "}\n",
    "\n",
    "def train(X, y, classifiers, size):\n",
    "    sss = StratifiedShuffleSplit(10, test_size=size, random_state=seed)\n",
    "    clfs = copy.deepcopy(classifiers)\n",
    "    \n",
    "    for clf in clfs.keys(): \n",
    "        c = clfs[clf]   \n",
    "        for meas in measures.keys():\n",
    "            c[meas] = []\n",
    "\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        for clf in clfs.keys():                    \n",
    "            c = clfs[clf]    \n",
    "            c[\"f\"].fit(X_train, y_train)\n",
    "            y_pred = np.asarray(c[\"f\"].predict(X_test))\n",
    "\n",
    "            for meas in measures.keys():\n",
    "                m = measures[meas]\n",
    "\n",
    "                if (meas != 'ck' and meas != 'acc' and meas != 'br'):\n",
    "                    c[meas].append(m(y_test, y_pred, average='macro'))\n",
    "                elif (meas == 'll'):\n",
    "                    c[meas].append(m(y_test, y_pred, labels=y_test))\n",
    "                else:\n",
    "                    c[meas].append(m(y_test, y_pred))\n",
    "    \n",
    "    return clfs\n",
    "\n",
    "result = train(X, y, classifiers, 0.3)\n",
    "                       \n",
    "for k in Xn.keys():\n",
    "    Xi = Xn[k]['X']\n",
    "    results = {}\n",
    "    for strategy in strategies:\n",
    "        results[strategy] = train(Xi[strategy], y, classifiers, 0.3)\n",
    "    Xn[k]['results'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_param3(cl, column):\n",
    "    results = pd.DataFrame(columns=measures)\n",
    "\n",
    "    for strategy in cl.keys():\n",
    "        for model in cl[strategy].keys():\n",
    "            res = [np.mean(cl[strategy][model][measure]) for measure in measures.keys()]\n",
    "            results.loc[strategy] = res\n",
    "\n",
    "    results = results.sort_index()\n",
    "    \n",
    "    figsize(10, 5)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ind = np.arange(results.shape[0])\n",
    "    width = 0.2\n",
    "    l = ax.plot(ind, results, \"-o\")\n",
    "    plt.legend(iter(l), results.columns.tolist(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlim([-0.25, ind[-1]+.25])\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(results.index)\n",
    "    plt.title(column)\n",
    "\n",
    "    plt.savefig(\"plots/\" + column + \"_missing_values.png\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for k in Xn.keys():\n",
    "    Xi = Xn[k]['results']\n",
    "    plot_param3(Xi, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_param4(cl, strategy):\n",
    "    results = pd.DataFrame(columns=measures)\n",
    "\n",
    "    for missingVal in cl.keys():\n",
    "        res = cl[missingVal]['results'][strategy]\n",
    "        for model in res.keys():\n",
    "            results.loc[missingVal] = [np.mean(res[model][measure]) for measure in measures.keys()]\n",
    "\n",
    "    results = results.sort_index()\n",
    "    \n",
    "    figsize(10, 5)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ind = np.arange(results.shape[0])\n",
    "    width = 0.2\n",
    "    l = ax.plot(ind, results, \"-o\")\n",
    "    plt.legend(iter(l), results.columns.tolist(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlim([-0.25, ind[-1]+.25])\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(results.index)\n",
    "    plt.title(strategy)\n",
    "\n",
    "    plt.savefig(\"plots/\" + strategy + \"_missing_values.png\")\n",
    "    plt.show()\n",
    "\n",
    "for strategy in strategies:\n",
    "    plot_param4(Xn, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_param5(cl):\n",
    "    results = pd.DataFrame(columns=measures)\n",
    "\n",
    "    res = {}\n",
    "    for strategy in strategies:\n",
    "        res[strategy] = {}\n",
    "        for measure in measures.keys():\n",
    "            res[strategy][measure] = []\n",
    "\n",
    "    for k in cl.keys():\n",
    "        Xi = cl[k]['results']\n",
    "        for strategy in Xi.keys():\n",
    "            for model in Xi[strategy].keys():\n",
    "                for measure in measures.keys():\n",
    "                    res[strategy][measure] = res[strategy][measure] + Xi[strategy][model][measure]\n",
    "\n",
    "    for strategy in strategies:\n",
    "        results.loc[strategy] = [(np.mean(res[strategy][measure])) for measure in measures.keys()]\n",
    "\n",
    "    results = results.sort_index()\n",
    "    \n",
    "    figsize(10, 5)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ind = np.arange(results.shape[0])\n",
    "    width = 0.2\n",
    "    l = ax.plot(ind, results, \"-o\")\n",
    "    plt.legend(iter(l), results.columns.tolist(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlim([-0.25, ind[-1]+.25])\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(results.index)\n",
    "    plt.title('Average')\n",
    "\n",
    "    plt.savefig(\"plots/average_missing_values.png\")\n",
    "    plt.show()\n",
    "\n",
    "plot_param5(Xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
